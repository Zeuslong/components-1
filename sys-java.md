# Java 基础

## Object

### ==

`==` 测试的两个引用是否指向了同一个对象。

比较引用时比较的是堆内存地址；比较基础数据类型时比较的是值是否相等。

> 基础数据类型：byte、short、char、int、float、long、double、boolean。

### equals()

 `equals()` 是 Object 类的一个方法，用来比较对象是否相等。

该方法可以被重写，在没有重写的时候，内部使用 `==` 操作符进行比较

> String、Integer、Date 这些类都重写了 equals() 方法

### hashCode()

`hashCode()` 是 Object 类的一个方法，用来计算对象的 hash 值。

`hashCode()`方法是本地方法，具体计算 hash 的值根据 JVM 的实现有不同，可以在启动 JVM 时通过 `--hashCode` 参数来指定使用特定的 hash 计算方式。

又因为 hash 计算本身可能会产生 hash 冲突，所以如果两个对象的 `hashCode()` 相同，它们并不一定相同。

### wait()

`wait()` 是 Object 类的一个方法，让当前线程让出锁，然后进入该对象的等待池，直到被唤醒。

再次被唤醒时，该线程需要重新获得锁权限才能继续执行。

当获取锁失败，或者自己放弃锁后，线程会被加入到当前对象的等待队列中去，等待被唤醒，也就是等待别的线程释放锁的时候，会唤醒该对象等待队列中的某一个或全部线程。（notify / notifyAll）

## notify()

唤醒当前对象上等待队列当中的线程。

`notify()` 是唤醒等待队列中的任意一个线程，而 `notifyAll()` 是唤醒等待池中的所有线程。

### clone()

`clone()` 是 Object 类的一个方法，是一种浅克隆的具体实现。

该方法返回一个不同地址的新对象，但是其中的引用还是原来对象当中的引用。

> 浅克隆：被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用仍然指向原来的对象。也就是说，浅复制仅仅复制所考虑的对象，而不复制它所引用的对象。
>
> 深克隆：被复制对象的所有变量都含有与原来的对象相同的值，那些引用其他对象的变量将指向被复制过的新对象，而不再是原有的那些被引用的对象。也就是说，深复制把要复制的对象所引用的对象都复制了一遍。

## String

### String 的实现

String 底层采用的是 `byte[]` 数组作为基础数据结构，由 coder 保存编码的方式，同时会缓存它的 hash 值用于比较两个 String 是否相等。

`byte[]` 数组通过 `final` 关键字修饰，所以是不可变的，可以在程序间共享。

### charAt()

因为 String 采用的 `byte[]` 数组作为数据结构，所以先会把查找的位置根据编码进行翻倍，比如 UTF-8 则是把 index * 2，再获取相邻的两个 byte 组合成 char 返回。

### equals() 

1. 先用 `==` 比较内存地址，相同则相等；
2. 如果不是，判断传入的对象是不是 String 类型；
3. 如果是，则比较两者的编码方式是不是一样；
4. 如果同种编码方式，再调用对应的编码方式，挨个比较里面的值；

### intern()

`intern()` 是一个 native 方法。它的作用是返回一个 String 常量。

如果常量池当中有一个包含了等同于此 String 对象的常量，那么就返回这个常量的引用，否则就在常量池当中创建这对象然后再返回这个对象的常量。

### 内存分配问题

所有通过 new 关键字创建的对象都在 **堆** 上面，而所有用 `""` 引用的对象都在常量池当中。

```
String index = new String("index");
/**
创建了两个对象：
"index" 在字符串常量池当中，如果字符常量里面没有 index 这个字面量，那么就会重新分配在字符常量池当中分配，如果有就算了
在堆当中创建了一个 String 的对象，然后其中的值引用了字符串常量池当中的字面量
**/
```

### String 、StringBuilder 与 StringBuffer

- String 不可变；
- StringBuilder 不是线程安全的，但是性能高；
- StringBuffer 内部使用 synchronized 是线程安全的，但是性能较低；

## 集合

### HashMap

#### 什么是 HashMap

HashMap 是一个 **key-value** 映射形式的 hash 表数据结构，它利用的 **数组** + **链表** + **树** 三种数据结构实现的。

#### get() 方法

get() 方法用来获取 HashMap 当中的某一个元素。

查询过程主要是通过用元素的 `hash 码`与 `table 的长度 - 1` 做**除余运算**然后找到桶位置，然后再加入到桶头节点或者桶上的链表/树当中去的，具体如下：

1. 检查 table 的合法性，如果不合法返回 `null`；
2. 计算桶位置，再依次通过 `equals()` 方法比较；
3. 如果当前桶位置的 key 和传入的参数 key 一样，那么就直接返回头节点；
4. 否则检查这个节点是不是 `TreeNode`，如果为 `TreeNode` 那么就返回 `getTreeNode()` 结果；
5. 否则遍历普通 `Node` ，如果找到一个 key 值与参数 key 相同的就返回，如果直到最后没有找到就返回 null；

#### put() 方法

`put()` 方法用来向 HashMap 当中添加一个元素，或替换已经存在的元素。

过程与 `get()` 方法过程类似，只是匹配到后做替换，未匹配到时在末尾插入，最后检测是否需要做扩容操作，具体如下：

1. 检查 table 是否为空，或者 table 的长度是否为 0 ，如果是的话，就执行 resize 方法进行 table 初始化；
2. 计算 hash 值找到桶位置，依次通过 `equals()` 方法比较；
3. 看当前桶位置是否为 **空**，如果为空就依据传进来的 key-value 创建 node 节点；
4. 如果不为空，就执行解决 hash 冲突的策略；
5. 用 `==` 与 `equals` 检查当前桶位置的 key 与传入的 key 是否相同，如果相同，那么就替换；
6. 检查该节点是否为 TreeNode 节点，如果是就执行 `putTreeVal()` 方法；
7. 如果是普通 Node 节点，依次查询这个链表上面的所有元素，查找是否有 key 值与传入的参数 key 相同的节点；
8. 如果在节点上找到元素，就替换；
9. 如果没有，就在末尾根据传入的参数新建节点；
10. 如果是替换操作，在替换完成的时候就返回 oldValue，如果是新增操作 `modCount + 1`，并且检查负载因子大小是否需要执行 `resize()`；

#### 扩容问题

##### 为什么要扩容

在数量变多的情况下，hash 冲突也会变多，每个桶的链表或者树节点会变多，导致查询效率慢。扩容则用来控制 hash 冲突、链表与树长度的一种方法。

##### 什么时候扩容

HashMap 是懒加载模式，在第一次插入时会触发扩容。

后续在 HashMap 的 size 大于等于 threshold 的时候会触发扩容。

> threashold = capacity * load factor

#### resize() 方法

`resize()` 方法主要是给 HashMap 当中的数据结构进行初始化或扩容。

最核心的地方在于要把原来链表上的元素重新散列到新的桶位置当中去，这个过程不是通过重新计算 hash 值的余数来完成的，而是通过 `(hash & oldCap) == 0` 来判断。`oldCap = 16`，加入桶的位置为 `hash % (oldCap - 1)`

1. 如果table == null，则为HashMap的初始化，生成空table返回即可；
2. 如果table不为空，需要重新计算table的长度，newLength = oldLength << 1(注，如果原oldLength已经到了上限，则newLength = oldLength)；
3. 遍历oldTable；
4. 首节点为空，本次循环结束;
5. 当前节点无后续节点，重新计算 hash 位，本次循环结束；
6. 当前是红黑树，走红黑树的重定位；
7. 当前是链表，JAVA 7 时还需要重新计算 hash 位，但是 JAVA 8 做了优化，通过 `(e.hash & oldCap) == 0` 来判断是否需要移位; 如果为真则在原位不动，否则则需要移动到当前 `hash槽位 + oldCap` 的位置;

散列冲突寻找新的桶位置的原理其实就是检测在新的长度下，最高位是否参与了最高位的计算，如果参与了计算那么就调整位置为一个循环，具体如下：

```
// 原理

/**

假设原本的容量为 16
对应的二进制为 0001 0000

新的容量为 32
对应的二进制为 0010 0000

对象的 hash = 0001 0101

那么在原有的桶位置为

0000 1111
0001 0101
---------
0000 0101 = 5

也就只有后4位起了作用

在新的桶位置的位置为

0001 1111
0001 0101
---------
0001 0101 = 21 = 5 + 16

便是后5位起了作用

而原本的桶容量的二进制刚好为五位，就可以验证 hash 码的第五位是否为 1 ，如果为 1 ，就需要改变对象在新桶当中的位置

**/
```

#### Hash 计算桶位置

hash 一般用来计算桶的位置，通过 `hash % table.length - 1` 的方式得到桶位置。

```
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 ： (h = key.hashCode()) ^ (h >>> 16);
    }
```

如果 key == null，那么 hash 默认为 0

如果不是，通过虚拟机为该 key 计算得到的一个 hashCode 值的前 16 位高位与后 16 位高位做异或运算然后得到一个 hash 值，这样做是为了混合原始 hash 值的高位和低位增加了低位的随机性。

#### HashMap 如何比较 Key

先求出 key 的`hashCode()`，比较其值是否相等，若相等再比较`equals()`，若 `equals()`相等则认为他们是相等的；若`equals()`不相等则认为他们不相等。

#### 当 Key 为自定义类时

当 Key 为自定义类时，需要重写 Key 的 `equals()` 方法与 `hashCode()` 方法。

> HashMap 中的比较 key 是这样的：先求出 key 的`hashCode()`，比较其值是否相等，若相等再比较`equals()`，若 `equals()`相等则认为他们是相等的；若`equals()`不相等则认为他们不相等。
>
>  如果只重写 `hashcode() ` 不重写 `equals()` 方法，当比较 `equals()` 时只是看他们是否为同一对象（即进行内存地址的比较），所以必定要两个方法一起重写。

#### 如何让 HashMap 散列更均匀

设置容量为 2 的幂次方。

当容量为 2 的幂次方的时候，由于做 hash 找 index 的过程是 length-1，而 2 的幂次方 -1 时得到的二进制码所有的位数都为 1，在计算 key 的时候就可以充分利用到 key 的 hash 的二进制码的所有位数，从而散列的均匀一点。

> 对应在 HashMap 当中，则是计算 Key 的桶位置时，使用的是 Key 的 `hashCode()` 与 `table.length - 1` 来计算桶位置。
>

#### 为什么 HashMap 中 table 长度要为 2 的幂次方

默认的初始容量为 `1<< 4 (16)`，当容量一定是 2^n 的时候，`length - 1` 得到的二进制上所有的位数都为 1，`h & (length - 1) == h % length` ，而按位运算会很快，散列更均匀。

#### HashMap 的负载因子是多少

HashMap 的 `load factory` 默认为为 **0.75**。

0.75 可以保证 HashMap 在 **时间** 和 **空间** 上有一个较好的平衡。太低的  `load factory` 会导致 HashMap 频繁的执行 `resize()` 方法来重新分配 table 空间；太高的  `load factory` 可以降低空间消耗，因为较高的值如果初识数量大于负载因子所限制的最大条目数，那么就不会发生 `resize` 操作，每个链表或者树上的节点就会变多，导致查找的开销增加。

#### fast-fail 策略

如果一个迭代器被创建了，一旦在迭代器中进行迭代时，HashMap 发生了结构变化，那么迭代器就会抛出异常 `ConcurrentModificationException`

#### HashMap 的死循环

HashMap 的死循环出现在并发环境下执行 `resize` 方法，当并发加入 put 的时候，引起扩容操作，然后多线程导致 HashMap 的 Entry 链表形成环形数据结构，查找时候会引起死循环。

> 具体的过程如下：
>
> 当有一个线程刚进入 get 方法的时候执行 `Entry next = e.next()` 方法后被挂起，然后新线程进入，并执行了扩容的操作，如果新的扩容后的链表的位置发生了反转，那么这个时候环形就形成了。
>
> 假如有两个线程 P1、P2，以及链表 `a->b->null`：
>
> 1. P1先执行，执行完`Entry<K，V> next = e.next;`代码后发生阻塞，或者其他情况不再执行下去，此时 `e=a，next=b`；
>
> 2. 而P2已经执行完整段代码，于是当前的新链表 `newTable[i] 为 b->a->null`；
>
> 3. P1又继续执行`Entry<K，V> next = e.next;`之后的代码，则执行完`e=next;`后，`newTable[i]`为`a<=>b`，则造成回路，`while(e!=null)`一直死循环；
>

#### HashMap 与 HashTable 区别

1. HashMap 不是线程安全的，HashTable 是线程安全的；

2. HashMap 允许 null 为键或值，Hashtable 不允许；

3. HashTable 直接使用对象的 hashCode 做运算，HashMap 会把 hashCode 的前后 16 位进行与运算；

4. 另一个区别是 HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器，而 Hashtable 的 enumerator 迭代器不是 fail-fast 的。所以当有其它线程改变了 HashMap 的结构（增加或者移除元素），在迭代过程中将会抛出ConcurrentModificationException

5. HashMap 的数组初始化默认容量为 16，Hashtable 默认为 11；

#### HashMap 与 TreeMap 的区别

1. HashMap 不保证顺序；TreeMap 能根据键来排序；

> TreeMap 默认用 Key 来升序排序，Iterator 遍历 TreeMap 得到的有序的结果。

#### 让 HashMap 同步

使用 Collctions 封装 HashMap 为 ConcurrentHashMap

```java
Map m = Collections.synchronizeMap(hashMap);
```

### ConcurrentHashMap

#### ConcurrentHashMap 数据结构

- 1.8 之前

  ConcurrentHashMap 当中维护一个 segment 数组，将元素分作若干部分，segment 继承了 ReentrantLock，在每一个 segment 当中又包含一个 HashEntry 数组。每一次并发都是第一次 hash 获取 segement 锁，再次 hash 找到元素。所以默认的 segment 数量为 16，也就只支持 16 个线程并发。

- 1.8 之后

  ConcurrentHashMap 当中维护了一个 Node 数组 + 链表/红黑树，Node 当中有 final 与 volatile 修饰的 value 数组。并发的方式改成了 synchronized 关键字控制。

> 在 ConcurrentHashMap 当中使用 volatile 关键来保证读取到工作内存当中的 table 都是最新的，所以 volatile 只会保证读取的时候数据是准确的。
>
> 在 ConcurrentHashMap 当中，如果要保证写入的时候操作是线程安全的话，那么还是需要 synchronized 来做线程同步操作。
>

#### ConcurrentHashMap 如何保证线程安全

ConcurrentHashMap 当中保证线程的安全性主要是通过 volatie、CAS、Synchronized 三个措施来保障线程安全性的。

##### 读安全

主要依靠 volatile 关键字。

在 ConcurrentHashMap 当中，用 volattile 来修饰 Node 数组，这样就保证了如果有一个线程修改了 Node 数组当中的数据，那么就会使读线程当中的 Node 数组无效，然后读线程就会重新在主内存当中去加载 Node 数组。

##### 写安全

主要依靠 CAS 与 Synchronized 关键字。

写操作主要涉及到如下几个步骤：

1. 获取 value 的桶位置（也是利用 hash 与 Node 数组长度除余来获得的）；
2. 获取 Node 结点（通过 Unsafe 类的 Volatile 语义的方法来获取的）；
3. 插入 Node 结点（CAS）；
4. 插入 Node 到链表当中去（加锁 Synchronized）；

其中，如果是插入 Node 节点时，由于插入结点这个操作不会对其它的数据有影响，所以就可以用 CAS 来替代锁住整个 Node 结点数组的过程，所以在并发的时候数组的其它 Node 节点同样是可以访问的，也就提高了并发量。

对于插入 Node 结点到链表或者树当中去这个操作，就需要获取锁来进行操作。

ConcurrentHahsMap 的查询操作只会保证获取到线程上的某一个时间的状态，而不会获取到最新的状态。这也就是说 ConcurrentHashMap 本身是没有采用读写锁，而在做更新操作的时候，根据更新的位置的不同来使用不同的并发处理方式，通常情况下不会对 Node 数组加锁，那么也就不会对大部分的读操作有锁定的影响，可以提升性能。

#### put() 方法

`put() ` 方法可向 ConcurrentHashMap 当中添加一个元素，或替换已经存在的元素，添加的元素不允许为 null。

ConcurrentHashMap 的更新操作与 HashMap 也大致相同，但其中采用了 CAS 更新方法、synchronized 关键字来同步线程。

ConcurrentHashMap 执行更新操作分作两种情况，一是当前插入的地方是一个空节点的，二是当前插入的地方已经存在一个元素。

如果插入的地方是一个空节点，那么利用 CAS 原理，把元素插入。

如果插入的地方已经存在一个元素，那么就要先获取这个元素所在的链表与树的锁，获取锁之前，要先检查是否有其它线程在扩容，那么有，则会完成扩容操作，然后获取这个结点的锁，从头开始遍历这个结点，遇到 hash 相同的就替换，否则末尾插入。

最后检查是否需要扩容或者转成树。

#### get() 方法

`get()` 方法用来获取 ConcurrentHashMap 当中的某一个元素。

ConcurrentHashMap 的查找过程与 HashMap 大致相同。但是在获取的时候有两个关键的地方，一是被 volatile 关键字修饰的 table，二是 tabAt 方法。

ConcurrentHashMap 的底层 table 是被 volatile 修饰的，也就是说，每一次要去使用 table 的时候，如果有别的线程修改了 table，那么当前线程的 table 缓存就会失效，然后去内存的当中重新获取 table 元素，保证了 table 是某一个时刻上面最新的。

然后计算桶位置，在 table 上面获取节点，这个时候 tabAt 方法调用了 Unsafe 类当中的 getObjectVolatile 方法，这个方法是拥有 volatile 语意的，可以以原子操作的模式，去内存当中根据对象地址和内存地址的偏移量直接获取对象，也保证了该对象在某一时刻的最新性。

然后获取到链表的头结点后，按照访问链表的方式来遍历链表，并且不需要加锁。

#### 为什么 ConcurrentHashMap 的参数都不能为空

ConcurrentHashmap 和 Hashtable 都是支持并发的，这样会有一个问题，当你通过 `get(k)`获取对应的 value 时，如果获取到的是 null 时，你无法判断，它是 `put（k，v）` 的时候 value 为 `null`，还是这个 key 从来没有做过映射。
HashMap是非并发的，可以通过 `contains(key)` 来做这个判断。而支持并发的 Map 在调用 `m.contains(key)` 和 `m.get(key)` ，由于读取未上锁，m 可能已经不同了。

#### ConcurrentHashMap 的特殊点

1. ConcurrentHashMap 是一个类似于 HashTable 的线程安全的 HashMap，它遵循了 HashTable 的功能规范，含有 HashTable 当中每个方法的方法版本，但是与 HashTable 同步的细节不相同；
2. 在访问 ConcurrentHashMap 的哈希表的时候，所有的操作都是要求是线程安全的，但是检索操作通常是不需要的，并且使用方法的所有参数都不能为空，也不允许存在空的 key 与 value；
3. 它的状态查询方法例如：`isEmpty()`、`size()` 都是反应某一个时刻的状态，其创建的迭代器也只是某一时刻所包含的键值对，并且只能被一个线程持有，而且不会有 ConcurrentModificationException；
4. ConcurrentHashMap 的 table 初始化发生在第一次插入的操作时候。

### ArrayList

#### 数据结构

内部是一个可改变大小的数组。当元素加入时，其大小将会动态地增长。

#### 访问特征

内部的元素可以直接通过 `get()` 与 `set()` 方法进行随机访问，速度很快。

#### 插入删除特征

插入时需要挪动元素位置，删除非头尾元素慢，新增元素慢。

由于需要预留一部分空间用于后续元素的插入，所以也相对比较浪费空间，较适用于无频繁增删的情况。

一直在末尾添加元素是，ArrayList 效率比 LinkedList 效率更高，ArrayList 虽然可能需要扩容，但是它的平均插入应该是 O(1)；LinkedList 在插入链表末尾的时候，不需要扩容，但是它的插入末尾需要移动指针到末尾，所以它的效率是 O(n)。

#### 线程安全

ArrayList 非线程安全。

### LinkedList

#### 数据结构

LinkedList 是一个链表，在添加和删除元素时具有比 ArrayList 更好的性能。

#### 访问特侦

访问时只能通过头节点依次遍历，在 `get()` 与 `set()` 方面弱于 ArrayList。

#### 插入特征

插入时只需要修改链表指针，不需要挪动位置。

适用于没有大规模的随机读取，有大量的增加/删除操作。随机访问很慢，增删操作很快，不耗费多余资源。

允许null元素。

#### 线程安全

非线程安全。

### Vector

#### 数据结构

Vector 类似于 ArrayList，底层是数组，但其是同步的，开销就比 ArrayList 要大。

#### 插入特征

Vector 和 ArrayList 在更多元素添加进来时会请求更大的空间。Vector 每次请求其大小的双倍空间，而 ArrayList 每次对 size 增长 50%。

#### 并发安全

使用 synchronized 保证并发安全。

## 并发

### 线程

#### 什么是进程

进程是计算机当中已运行程序的实体，是操作系统分配资源的最小单位。

> 资源：例如内存空间 CPU 资源等等。

#### 什么是线程

线程是进程当中的一个任务的描述，是操作系统调度执行的最小单位。

一个进程当中含有多个线程，线程可以利用进程所拥有的资源。

#### 线程与进程的区别

1. 进程是操作系统分配资源的最小单位，而线程是独立运行和独立调度的基本单位。
2. 进程享有独立的内存单元，而多个线程共享进程的内存空间。
3. 二者均可并发执行，但是进程的创建和销毁需要系统对进程分配或销毁所以线程在并发过程中的创建、切换、销毁成本更低。

#### 线程的生命周期

- 新建状态：当一个线程被关键字 `new` 创建出来的时候，就处于新建状态，JVM 为其分配内存空间与初始化其成员变量；
- 就绪状态：当一个线程执行 `start()` 方法后，或者当一个线程正在等待被调度运行的时候，就处于就绪状态；
- 运行状态：当一个线程得到了系统资源，开始执行 `run()` 方法当中的代码后，就处于运行状态；
- 阻塞状态：线程主动的让出 cpu 资源，等待某条件满足的状态，就处于阻塞状态；
- 死亡状态：当一个线程执行完 `run` 方法后，或者执行 `interrupt` 方法强制中断线程，就处于死亡状态；

> 进入阻塞状态：1.执行 `sleep` 方法主动让出 cpu 资源；2.等待 IO 完成；3.执行 `wait` 后等待被唤醒；4.等待获取锁权限。

#### start() 与 run()

`run()` 方法当中封装的是多线程需要处理的任务逻辑代码，如果单独执行`run()` 方法那么线程没有成功启动而只是在本线程当中执行。

`start()` 方法是新创建的线程执行，而且 `start()` 内部调用了 `run()` 方法。

#### Runnable 与 Callable

Runnable 接口不返回任何结果。

Callable 则需要返回结果。

#### Runnable 与 Thread

采用 Thread 的时候，只能继承一个类，如果这个类需要继承其它类则不考虑 Thread。

如果使用 Runnable 实现接口能够更好的独立出逻辑块，因为一个 Runnable 通常被理解为一个任务。

#### interrupted() 与 isInterrupted() 

两者都是调用 `isInterrupted(boolean ClearInterrupted)` 方法，来判断当前运行的线程是否被中断了。

interrupted 传递的参数为 `true` 也就是会重置 `interrupted state` 状态变量，也就是说如果第二次调用，这个期间当前线程只被中断过一次的话，就会返回 `false`。

isInterruptedd 传递的参数为 `false` 不会重置 `interrupted state` 状态变量。

*!* `interrupted state` 用来标识当前线程是否被中断了。

#### notify() 与 notifyAll() 

`notify()` 方法是用来唤醒等待队列当中某一个线程进入到锁队列当中去参与锁竞争。

`notifyAll()` 方法则是唤醒等待队列当中的所有的线程到锁队列当中参与锁的竞争。

> 在 Java 的并发当中所有的对象都存在一个 `锁队列` 和 `等待队列`，当执行对象的 `wait()` 方法的时候，就会把执行的线程加入到等待队列当中，等待队列当中的线程不参与锁的竞争。

#### wait() 和 sleep() 

`wait()` 的含义是在本对象的等待队列上等待被其它唤醒，不仅仅要放弃当前所获得的锁权限，而且在没有被唤醒的时候不参与锁的竞争。

`sleep()` 的含义是休眠该线程，也就是阻塞的意思，不会放弃当前线程的锁权限，也不会放弃争夺锁的权限。

#### ThreadLocal

JVM 会给每个对象单独分配一块内存空间，这块空间就叫 ThreadLocal。

通过 ThreadLocal 线程可以把原本在内存共享区域的数据拷贝到自己的线程内存上面，如果线程可以做到只修改这块空间中的数据而不会影响到主内存当中原本的数据。

ThreadLocal 是一个类，要使用到 ThreadLocal 需要内部持有这个类，ThreadLocal 内部有 get 和 set 方法来满足大部分需求，TheadLocal 利用 ThreadLocalMap 来存取对象，Map 当中 key 为 ThreadLocal 自己，value 为值。

> ThreadLocal 是一种用空间换取线程安全的做法。

#### Java 线程调度算法

采用抢占式算法。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

Java 采用抢占式线程调度的方法，每个线程由操作系统来分配时间，线程的切换不由线程本身来决定，在这种调度方式下，线程的执行时间是系统可控的，不会导致由于一个线程使整个进程阻塞的问题。

Java 当中也可以设置优先度，在 Java 当中有 10 个级别的优先度分别来映射操作系统上的优先级，可能没有办法一一对应，所以并不是很可靠，所以最终还是要取决与操作系统。

### 锁

#### 独享锁与共享锁

独享锁是指该锁一次只能被一个线程所持有。

共享锁是指该锁可被多个线程所持有。

ReentrantLock、Synchronized 是独享锁；ReadWriteLock 其读锁是共享锁，其写锁是独享锁。

#### 公平锁与非公平锁

公平锁指的是有多个线程申请锁的时候，按照线程申请的先后顺序来获取锁。

非公平锁指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。

synchronized 是非公平锁；ReentrantLock 可以通过构造方法指定是公平锁还是非公平锁。

##### 比较

事实上公平的锁机制往往没有非公平的效率高，在锁的快速且重复的获取过程中，连续获取的概率是非常高的，而公平锁会压制这种情况，虽然公平性得以保障，但是响应比却下降了。此外，因为公平的获取锁没有考虑到操作系统对线程的调度因素，这样造成 JVM 对于等待中的线程调度次序和操作系统对线程的调度之间的不匹配。

公平锁能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。

#### 互斥锁

互斥锁独享锁具体的实现，一次只能被一个线程所持有。

ReentrantLock 就是互斥锁。

#### 读写锁

读写锁就是共享锁的具体实现。在写入的时候只允许一个线程执行读写，当没有写入操作时，可以允许多个读操作并发执行读。

读写锁在 Java 中的具体实现就是 ReadWriteLock。

#### 乐观锁与悲观锁

乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。

##### 悲观锁

悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。

悲观锁适合写操作非常多的场景。在 Java 中的使用，就是利用各种锁。

##### 乐观锁

乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断的更新数据。乐观的认为，不加锁的并发操作是没有事情的。

乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。在 Java 中的使用，是无锁编程，常常采用的是 CAS 算法，典型的例子就是原子类，通过 CAS 自旋实现原子操作的更新。

#### 重入锁

重入锁指的是一个线程能够对一个临界资源重复加锁。例如，是当一个线程获取到一个对象的锁并执行其中的方法时，它调用这个对象当中的另外的一个方法，可以不用再进入锁队列去抢占锁的控制权，可以直接调用另外的一个方法。

在 Java 当中，ReentrantLock、synchronized 是重入锁。

### CAS 算法

CAS 全称为比较与交换（Compare and Swap）。

CAS 会先-备份旧的数据，然后基于旧的数据进行修改数据，当数据修改完成后，比较备份的旧数据与当前内存当中的数据，如果相等，则证明共享数据没有被修改，替换成新值；如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。

### AbstractQueuedSynchronized

AQS 提供阻塞和唤醒线程功能以及队列模型的简单框架，许多同步类实现都依赖于它，如常用的 ReentrantLock。

#### 基础结构

AQS 内部维护一个单向列表，每个请求共享资源的线程封装成队列当中得一个节点。如果有线程来请求共享资源，在贡献资源空闲时，就把请求的这条线程设置为有效的工作线程，将共享资源设置为锁定状态；如果贡献资源被占用，就将获取不到锁的线程加入到单项链表种，等待工作线程释放锁。

AQS 中还维护了一个名为 state 的字段，意为同步状态，是由 Volatile 修饰，用于展示当前临界资源的获锁情况。子类可以通过修改 State 字段来实现多线程的独占模式或者共享模式。

### ReentrantLock

ReentrantLock 是一个重入锁，默认采用非公平锁竞争方式，也可以通过构造方法来指定其是否是一个公平锁。

#### 实现原理

其内部是通过扩展 AQS(AbstractQueuedSynchronizer) 来实现的。

```java
Lock lock = new ReentranLock();
lock.lock();
try{
    //do something
}finally{
    lock.unlock();
}
```

#### 获取锁

获取锁的过程主要与两个东西相关：

1. AQS，阻塞的线程都放在这个队列当中；
2. state 状态码，表示进入线程的次数，每重入一次会 +1，每释放一次 -1；

ReentrantLock 的 lock 依赖 AQS 的 acquire 方法。

在 AQS 的 acquire 方法当中，线程获取当前的锁，主要有两个过程：1.尝试获取锁过程；2.进入阻塞队列。

尝试获取锁的过程：

首先判断 AQS 的 state 是否等于 0，state 为 0 则表示锁没有人占有，接着判断队列是否有排在前面的线程在等待锁，没有的话使用 cas 的方式修改 state，最后线程获取锁成功，然后将线程记录为独占锁的线程。

若果前面有人占着锁，就会检查是否是当前线程，如果是当前线程就继续执行。

如果两个判断都没有执行通过，就加入等待队列。

加入队列的时候使用的是一个死循环，保证一定会插入到队列当中，在加入等待队列的时候，Node 对象的初始化，会自动的获取当前线程，并传入到 Node 当中持有。

如果没有获取到锁并且成功的加入到等待队列当中后，就会中断当前线程。

#### 释放锁

释放锁的时候，主要对比当前的线程与当前锁拥有者是否一致，然后在改变 AQS 当中的 state 状态码，表示有一个线程已经退出。

> 在 AQS 当中有一个 state 状态码，用来维护当前线程进入的次数，保证线程的重入时候要释放相同次数，也是其它线程获取锁的一个参考参数。
>
> 然后通过 AQS 获取队列当中的线程来解除临界资源的占用。
>

## NIO

### 阻塞/非阻塞与同步/异步

阻塞与非阻塞指的是等待数据的一种方式。

阻塞指的是数据还没有就绪时，就等待数据，直到数据就绪后再继续执行；非阻塞在数据没有就绪时，会直接返回，继续执行当前方法。

同步与异步指的是查询数据是否就绪的方式。

同步指的是主动轮询各个数据准备的状态；异步指的是数据就位后通知进程数据已经就位。

综上，阻塞与非阻塞，讨论的是进程想要获取结果的时候的一种状态（等或者不等），而异步与同步讨论的是，消费者获取服务者任务执行状态的一种方式。

### 什么是 NIO

NIO 叫做 nonblocking IO，是一种同步非阻塞的 IO 方式。

在普通的 IO 当中，当应用程序需要进行 IO 的时候，它会去调用系统当中的方法，这个系统调用会导致应用程序的阻塞，然后等待操作系统将数据拷贝到内核当中，再从内核拷贝到用户进程当中，只有到数据全部准备好之后，应用程序才会被唤醒，再进行数据的处理。

而 Java 当中的 NIO，在执行系统调用后，系统会立即给应用程序返回，然后 Java NIO 应用程序就不需要再等待，但是它会每一隔一段时间再来获取系统当中 IO 的状态，如果数据没有准备好的话，就会返回一个 ERROR，当数据返回后应用程序不需要再等待，可以继续做其它的事情，然后不断的对系统进行轮询直到找到自己可以用的数据为止。

### Java NIO 模型

Java NIO 模型是基于反应器模式来设计的。

Channel 把自己注册到 Selector 上面去，然后告诉 Selector 这个 Channel 所关心的事情，然后应用程序就会接着做别的事情。

Selector 会反复的对数据进行轮询，当 Channel 所感兴趣的事情发生的时候，Selector 就会唤醒这个 Channel 然后执行操作。

### NIO 主要组件

#### Channel

Channel 叫做管道，向 Buffer 当中写入数据，或者读取数据

- FileChannel

文件的数据读写

- DatagramChannel

UDP 数据的读写

- SocketChannel

TCP 数据的读写

- ServerSocketChannel

允许我们监听TCP链接请求，每个请求会创建会一个SocketChannel

#### Buffer

缓存区，主要是暂时保存 Channel 写入的数据，也是让 Channel 读取数据的地方

利用Buffer读写数据，通常遵循四个步骤：

```java
    把数据写入buffer；
    调用flip；
    从Buffer中读取数据；
    调用buffer.clear()或者buffer.compact()
```

具体的实现：

- ByteBuffer
- MappedByteBuffer
- CharBuffer
- DoubleBuffer
- FloatBuffer
- IntBuffer
- LongBuffer
- ShortBuffer

#### Selector

注册对各种 I/O 事件的兴趣的地方，而且当那些事件发生时，Selector 就会告诉您所发生的事件。

### FileChannel

FileChannel 是 Java NIO 类库当中处理文件数据的一个抽象类，虽然是 NIO 类库当中的一员，但是 FileChannel 在读取与写入数据的时候，依旧是阻塞的，也就是说在 FileChannel 在读入数据的时候，还是要等到数据进入到操作系统内核内存，然后再从内核读入进程内存，然后才可以开始操作。

但是个人认为 FileChannel 的出现对于 Java IO 体系来讲并不是多余的。网上流传的 NIO 有很多种含义：1.Non-blocking IO。2.New IO。第一种含义意思是非阻塞的 IO，也就是当我们执行其中的某些方法的时候，当方法没有执行完毕的时候，原本是应该被阻塞的，但是在非阻塞的 IO 方式当中，就算没有执行完毕，也是可以直接返回的。第二种含义的意思是一种新的 IO 思维，NIO 所有的 IO 类后都有一个后缀叫做 Channel，Channel 译过来是通道的意思，这一种含义更贴近 FileChannel 的设计理念，FileChannel 是一个双向操作的 IO 流，传入对应的文件路径并且打开 FileChannel 之后既可以执行读操作也可以执行写操作，在这样的工作机制下，当我们需要对文件进行操作的时候，只需要打开对应文件的 FileChannel，再申请一个 Buffer 就可以直接操作，不用关心读取的时候的一些细节的控制。

# JVM

## 并发

### Sychronized

Synchronized 是 Java 内置的一个关键字，用来防止资源冲突，当任务要执行被 synchronized 关键字保护的代码片段的时候，它将检查片段的锁是否被别的线程持有，然后获取锁，执行代码，释放锁。

#### 原理

在 JVM 中所有的对象都自动含有单一的锁，也叫做监视器。当在某一个对象上面调用任意的 synchronized 方法的时候，这个对象会被锁定，这时候其它再来请求该对象其它的 synchronized 方法只有等到前一个方法调用完毕并释放了锁之后才能被调用。所以在同一个对象当中，所有的 synchronized 的方法共享同一个锁。

#### 实现机制

synchronized 方法的实现第一步在编译成字节码的时候就开始了，JVM 的字节码中被 synchronized 修饰的方法在的 Class 文件方法表当中 access_flag 字段当中的 synchronized 标记为 1 表示是一个同步的方法。

编译器会把 synchronized 块编译成 `monitorenter` 与 `monitorexit` 包裹的代码块，然后把方法翻译成普通的方法。

JVM 被要求保证当线程执行到 `monitorenter` 与 `monitorexit` 要成对使用，并且任何一个对象都必须关联一个 monitor，当这个对象的 monitor 被持有后，将处于锁定的状态，不允许其它的线程进入到 monitor 的代码块。

当线程执行 `monitorenter` 的时候，对应的 monitor 对象会被锁定，然后触发对象的 monitor record 列表来获取锁的相关信息，退出便释放锁，如果 monitor 被持有，获取失败，也会刷新 monitor record 列表来获取锁信息。

### Volatile

被 Volatile 修饰的成员变量具有两成含义

1. 保证了不同线程对这个变量的修改对于其它的线程来讲是立即可见的
2. 禁止指令重排序

```java
//线程1
boolean stop = false;
while(!stop){
    doSomething();
}

//线程2
stop = true;
```

这段代码有可能导致无法中断线程，当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程 2 转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。

用volatile修饰之后

第一：使用volatile关键字会强制将修改的值立即写入主存；

第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；

第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。

那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，
然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。

那么线程1读取到的就是最新的正确的值。

#### Volatile 实现原理

如果对声明了 volatile 变量进行写操作时，JVM 会向处理器发送一条 Lock 前缀的指令，JVM 会对 LOCK 进行特殊处理。

#### Volatile 可见性实现

如果对声明了 volatile 变量进行写操作时，JVM 会向处理器发送一条 Lock 前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了 volatile 变量进行修改，则立即更新主内存中数据。

在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，
会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了 volatile 变量都是从主内存中获取最新的。

#### Volatile 有序性实现

Lock 前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面。
即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。

#### i++ 是原子操作吗

不是

i++ 要经历三个过程：

1. 读取 i 值
2. 计算 i 值
3. 写回 i 值

这三个过程都可能被打断

### Monitor

Monitor 是一个同步机制，也是一个对象。

所有的 Java 对象从被创建起就关联一个 Monitor 对象，所以每个对象都有一把锁，叫做内部锁或者 Monitor 锁。

#### Monitor Record

monitor record 是线程私有的

Owner：初始时为NULL表示当前没有任何线程拥有该 monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为 NULL；

EntryQ：关联一个系统互斥锁（semaphore），阻塞所有试图锁住 monitor record 失败的线程。

RcThis：表示 blocked 或 waiting 在该 monitor record 上的所有线程的个数。

Nest：用来实现重入锁的计数。

HashCode：保存从对象头拷贝过来的 HashCode 值（可能还包含 GC age）。

Candidate：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。

Candidate 只有两种可能的值： 0 表示没有需要唤醒的线程，1 表示要唤醒一个继任线程来竞争锁。

### 对象头

在对象头当中存放了两部分信息：Mark Word(标记字段)、Klass Pointer(类型指针)。

Mark word 用来存放对象运行时候的数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。

Klass Pointer 用来指向这个对象的 类 元数据信息，可以根据 Klass Pointer 来判断该对象属于哪个类。

#### 对象头大小

如果对象为普通对象，对象头一般占两个机器码，在 32 位虚拟机上，1 个机器码占 4 字节，也就是 32 bit。

如果对象为数组，对象头占三个机器码，因为 JVM 可以通过对象的元数据信息确定对象的大小，但是无法从数据的元数据信息确认数组的大小，所以多余的一块用来记录数组的大小。

对象头信息是对象自身数据之外的信息，所以为了考虑到空间，对象头当中的 Mark Word 一般被设计成为一个非固定的数据结构以便在极小的空间内存放更多的数据。

### 锁优化



## 内存模型

### 什么是内存模型

内存模型是针对并发一块来讲的，C 与 C++ 语言在并发上都是使用物理硬件和操作系统的内存模型，就会导致在一个平台上并发没有问题，但是在另外一个平台上就会有线程安全的问题，所以 Java 为了在程序在各种平台下都能达到一致的内存访问效果，定了一种 Java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异。

Java 内存模型包括两部分：

1. 主内存与工作内存的交互模型；
2. 主内存与工作内存的交互规则；

### 主内存和工作内存的交互模型

Java 内存模型规定了所有的变量都存储在主内存中。每条线程中还有自己的工作内存，线程的工作内存中保存了被该线程所使用到的变量（这些变量是从主内存中拷贝而来）。
线程对变量的所有操作（读取，赋值）都必须在工作内存中进行。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

### 主内存与工作内存的交互规则

内存交换原则分作两个小块，1.变量交互规则。2.volatile 的特殊规定。

### 内存模型的实现

#### 指令重排序

在执行程序时，为了提高性能，编译器和处理器会对指令做重排序。但是，JMM确保在不同的编译器和不同的处理器平台之上，通过插入特定类型的Memory Barrier来禁止特定类型的编译器重排序和处理器重排序，为上层提供一致的内存可见性保证。

1. 编译器优化重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；
2. 指令级并行的重排序：如果不存l在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；
3. 内存系统的重排序：处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行；

#### 数据依赖

如果两个操作访问同一个变量，其中一个为写操作，此时这两个操作之间存在数据依赖性。

编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序，即不会重排序。

#### as-if-serial

不管怎么重排序，单线程下的执行结果不能被改变，编译器、runtime 和处理器都必须遵守 as-if-serial 语义。

#### 内存屏障（Memory Barrier ）

通过内存屏障可以禁止特定类型处理器的重排序，从而让程序按我们预想的流程去执行。内存屏障，又称内存栅栏，是一个CPU指令

编译器和 CPU 能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条 Memory Barrier 会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。

Memory Barrier 所做的另外一件事是强制刷出各种 CPU cache，如一个 Write-Barrier（写入屏障）将刷出所有在 Barrier 之前写入 cache 的数据，因此，任何 CPU 上的线程都能读取到这些数据的最新版本。

如果一个变量是 volatile 修饰的，JMM 会在写入这个字段之后插进一个 Write-Barrier 指令，并在读这个字段之前插入一个 Read-Barrier 指令。

这意味着，如果写入一个 volatile 变量，就可以保证，一个线程写入变量 a 后，任何线程访问该变量都会拿到最新值。

#### happens-before 原则

在内存模型当中中，如果一个操作的执行结果需要对另一个操作可见，那么这两个操作之间必须要存在 happens-before 关系，这个的两个操作既可以在同一个线程，
也可以在不同的两个线程中。

监视器锁规则：对一个锁的解锁操作，happens-before 于随后对这个锁的加锁操作。

传递性规则：如果 A happens-before B，且 B happens-before C，那么 A happens-before C。

### 可见性

可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。

而普通的共享变量不能保证可见性，普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。

```java
//线程1执行的代码
int i = 0;

i = 10;

//线程2执行的代码
j = i;

```

由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到工作内存中，然后赋值为10，那么在线程1的工作内存当中i的值变为10了，却没有立即写入到主存当中。

此时线程2执行 j = i，它会先去主存读取i的值并加载到线程2的工作内存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.

### 有序性

即程序执行的顺序按照代码的先后顺序执行。

在 CPU 执行的时候，可能会把代码的顺序打乱，然后来提高执行的效率，叫做指令重排序，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。

在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，synchronized和Lock保证每个时刻是有一个线程执行同步代码，
相当于是让线程顺序执行同步代码，就保证了有序性。

### 原子性

即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

在 Java 当中只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作

```Java
int x = 10;
int y = x;
x++;
x = x + 1;
```

咋一看，可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。

语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。

语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。

同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。

所以上面4个语句只有语句1的操作具备原子性。

## 内存区域

### JVM 内存区域划分

根据 《Java 虚拟机规范》的规定，运行时数据区通常包括这几个部分: 

- 程序计数器（Program Counter Register）
- 方法区（Method Area）
- Java 栈（VM stack）
- 本地方法栈（Native Method Stack）
- Java 堆 （VM heap）

JVM 规范当中虽然规定了程序在执行期间运行时数据区应该包括几部分，具体实现没有做规定。

### 程序计数器

程序计数器存储的是当前线程所要执行的下一条字节码指令的地址，Java 是多线程的，所以程序计数器是线程独立的才能保证线程之间不会相互干扰

Jvm 规范当中规定，如果线程执行的非 Navive 的方法，则程序计数器当中保存的是需要执行的指令的地址，如果线程执行的是 navive 方法，那么程序计数器中的值是 undefined

由于程序计数器当中的存储的数据所占空间的大小不会随程序的改变而改变，所以程序计数器没有设定 OutOfMemory Exception 异常

### 方法区

方法区当中存储已经被虚拟机加载的 类信息 常量 静态变量 即使编译器编译后的代码等数据

如果一个类被 ClassLoader 加载，那么就会在方法区生成一个代表该类的 Class 对象(唯一一种不在堆上生成的对象)，该对象将作为程序访问方法区当中该类的信息的外部接口，该类也是实现 **反射** 的基础

因为所有被加载到内存的 Class 信息应该被所线程都能获取到，所以方法区是线程共享的

Java 7 之前，HotSpot 将 Gc 分代收集扩展到了方法区，使用永久代来实现方法区，主要针对常量池的回收和类的卸载

Java 7 之后，逐渐将方法区从永久代移除，Java 7 已经将运行时常量池永久从永久代移除，在 Java 堆当中开辟了一块内存区域存放运行时常量池

Java 8，永久代被彻底移除，将方法区放到了一个与堆不相连的区域，叫做元空间

规定了一种异常

- OutOfMemoryError 当方法区无法满足内存分配的需求时

### Java 栈

 Java 栈就是我们常说的栈，也是 Java 方法执行的内存模型

 栈当中存放的是栈帧，一个栈帧对应的是一个被调用的方法，其中包括 局部变量表(Local Variable) 操作数栈(Operand Stack) 指向当前方法所属类的运行时常量池的引用(Reference to runtime constant pool) 方法返回地址(Return Address) 和一些额外的信息

 每一个方法从调用直至执行完成的过程，就对应一个栈帧在薯泥机中入栈到出栈的过程

 每一个线程执行的方法集不一样，所以每一个线程都有自己的一个 Java 栈，保持线程的独立性

 Java 栈当中规定了两个异常情况

 - StackOverFlowError 线程请求的栈深度大于虚拟机所允许的栈深度
 - OutOfMemoryError 虚拟机栈动态扩展时无法申请足够的内存

### 本地方法栈

本地方法栈与 Java 栈的作用相似，但是本地方法栈是为本地方法提供支持的

HotSpot 虚拟机将本地方法栈和虚拟机栈合二为一

本地方法栈定义了两个异常情况

 - StackOverFlowError 线程请求的栈深度大于虚拟机所允许的栈深度
 - OutOfMemoryError 虚拟机栈动态扩展时无法申请足够的内存

### Java 堆

Java 堆用来存放对象和数组，基本上所有的对象都存放在 Java 的堆空间上

Java 堆是线程共享的，所以当多个线程持有指向同一个堆当中的对象的时候，就会发生并发安全问题

Java 堆是 GC 主要关注的区域，按照 GC 的角度来观察，Java 堆被分作 新生代和老年代

Java 堆被要求是逻辑上相连的，但它可以不是物理上相连接的

规定了一种异常

- OutOfMemoryError 表示在堆上没有内存再完成实例的分配，而且也无法扩展堆的内存大小

### 内存泄漏与内存溢出

内存泄露: 指在内存当中的对象无法再被 GC 回收而一直占用内存块。

内存溢出: 指程序执行过程当中，无法申请到足够的内存空间的一种情况。

### static 的代码块

static 修饰的变量会进入到方法区当中

static 修饰的代码也应该要进入到内存当中，因为字节码文件只是静态的文件代码，需要加载到内存当中才能成为可动态运行的对象

### 工作内存的回收

工作内存主要是线程的内存块，里面主要包含有栈。

栈里面的空间，主要是栈帧在使用，其中包括局部变量表、操作数栈、动态链接等等信息，这些信息在弹出栈并且使用完后会被自动清理。

### 常量池

#### 静态常量池

静态常量池是 Class 文件当中的一部分。我理解为 Class 文件的资源仓库，主要存储字面量(例如，文本字符串 & 声明为 final 的常量值等)和符号引用(例如类和接口的全限定命 & 字段的名称和描述符 & 方法的名称和描述符)

#### 动态常量池

动态常量池是方法区的一部分。它主要在 Class 被加载进入内存时用来存放 Class 文件当中编译时期生成的各种字面量和符号引用。

#### String 实例与常量池

```
  String s1 = new String("abc");

```

在这里，至少创建了两个对象，第一个对象在常量池当中，为 "abc"，执行这条语句的时候，需要去检查常量池当中是否有这样一个字面量，如果没有就需要创建，当确定字面量之后，就用这个字面量来创建字符串实例。

```
    String index = "a";
```

这句话会产生两个东西，第一个是 Javac 在编译的时候会把 "a" 和 index 的符号引用写入到 class 文件的常量池当中，这个时候只能被看作是数据，在程序运行的时候，index 与 "a" 会被读入内存当中，这个时候就变成了 String 类的实例，具有 String 的所有的方法。

## GC

### 什么是 GC

在 Java 中 GC 主要负责回收未使用到的对象，部分 GC 算法还负责整理内存碎片。

### GC 可达性分析

从一系列 GC ROOTs 的对象开始查找，从这些节点向下搜索这些 GC ROOT 的引用链，如果一个对象不在任何一条引用链上，那么这个对象就是不可用的

*!* 可作为 GC ROOT 的对象有一下几种

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 方法区中（也就是那些被加载到内存当中的 Class 对象）静态属性引用的对象
- 方法区当中（也就是那些呗加载到内训当中的 Class 对象）常量引用的对象
- 本地方法栈当中 JNI(一般所谓的 Native) 引用的对象

### GC 引用计数法

给对象添加一个引用计数器，每当有一个地方引用它的时候，计数器便加一，引用失效的时候，计数器便减一，当计数器为 0 的时候，这个对象就是不可再用的了

引用计数法没有办法很好的解决两个对象相互循环引用的问题，也就是 A 引用 B，B 引用 A，这样 AB 两个对象永久在内存当中不会被回收。

### GC 回收算法

#### 标记-清除法

标记清除算法分作两个阶段，第一个标记阶段标记处所有不可用的对象，在第二个阶段清除这些阶段

两个不足:

1. 标记和清除阶段的执行效率都不高
2. 清除阶段过后会产生大量的不连续的空间，这样就可能导致空间的随便较多，无法分配需要内存空间较大的对象

#### 标记-清除法

标记 - 整理算法同样分作两个阶段，第一个阶段标记所有不可用的对象，第二个阶段让所有存活的对象都向一端移动，然后清除边界以外的所有内存

标记 - 整理算法主要针对老年代，老年代的对象都是长期存活的对象，所以如果用复制算法就需要额外的内存空间担保，所以班老年代都不采用复制算法

#### 复制算法

复制算法把内存分作两部分，每次分配都只使用其中的一部分，当使用的部分快要用完的时候，就把这部分当中所有可用的对象复制到另外一块内存空间上，然后一次性清除块占满的哪一块内存空间

复制算法解决了 标记 - 清除算法效率不高的问题，同时只回收半块内存空间，所以不考虑内存碎片的问题

98% 的对象的周期都很短，为了提高内存空间的使用，一般来讲，不是按 1:1 来划分空间，而是把内存空间划分为一块较大的 Eden 和两块较小的 Survivor，其中 Eden : Survivor = 8:1，每一次只使用其中一块 Eden 与 Survivor，当需要进行垃圾把 Eden 与 Survivor 当中还存活的对象复制到另外一块没有使用的 Survivor 内存空间上

对于 HotSpot 来讲，因为 Survivor 的空间较小，所以可能会出现整理后对象复制到 Survivor 上没有足够的内存空间，所以这个时候就会有一个担保规则

*!* 空间担保规则: 在发生 Minor GC 前，虚拟机会检查老年代的可用的连续空间是否大于新生代所有对象总空间，如果大于，那么这个 Minor GC 就是安全的，便可以用老年代进行空间担保. 如果老年代空间不足，那么就需要进行一次 Full GC.

### GC 的内存分代

虚拟机中的共划分为三个代：年轻代（Young Generation）、年老点（Old Generation）和持久代（Permanent Generation）。其中持久代主要存放的是Java类的类信息，

#### 年轻代

所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，
两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，
此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。

#### 老年代

在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。

*!* 特殊情况：大对象会被直接分配到老年代

#### 持久代

用于存放静态文件，如今Java类、方法等。

### GC 两个过程

#### Minor GC

回收新生代垃圾

当 Eden 区的空间占满的时候，会触发 Minor GC。

MajorGC采用标记—清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC的耗时比较长，因为要扫描再回收。MajorGC会产生内存碎片，为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。

执行 Minor GC 操作时，不会影响到永久代。从永久代到年轻代的引用被当成 GC roots，从年轻代到永久代的引用在标记阶段被直接忽略掉。

大部分 Eden 区中的对象都能被认为是垃圾，永远也不会被复制到 Survivor 区或者老年代空间。所以 Minor GC 导致的 Stop-the-World 所需要的时间会很短。

#### Major GC

回收老年代垃圾

### GC 收集器

垃圾收集器是 GC 算法的具体实现，需要根据老年代与新生代的特征来具体设计，JVM 规范当中没有强制限定的要求

新生代垃圾收集器: **Serial** **ParNew** **Parallel Scavenge**

老年代垃圾收集器: **CMS** **Serial Old** **Parallel Old**

全能收集器: **G1**

#### G1

G1 面向服务端应用的垃圾回收器，负责管理整个堆内存

G1 相对其它的收集器具有如下四个特点

1. 并行与并发 依旧能用多线程的优势处理垃圾
2. 分代收集 依旧把对象根据年龄分代
3. 空间整合 采用标记 - 整理的算法，局部采用复制算法，不会产生碎片
4. 可预测的停顿 可以让使用者规定在运行的 M 时间当中，停顿时间最长为 N

G1 收集器的过程可以分成以下几个步骤

1. 初始标记 (Stop the world，标记 GC ROOT 能直接关联到的对象)
2. 并发标记 (可以与用户线程并发，从 GC ROOT 进行可达性分析)
3. 最终标记 (Stop the wolrd 但是是可以与用户线程并发的，主要是修正之前的标记)
4. 筛选回收 (因为只有部分空间而且停顿时间很短所以建议 Stop the world 但是是可以并发的，这个阶段对各个 Region 的价值进行排序，根据设定来执行回收)

##### G1 内存化整为零的思路

把 Java 堆分作多个大小相等独立区域，这个独立区域(Region)，把对象分配在这独立区域上面，当要发生 GC 的时候，就只在这些 Region 上面发生，虚拟机根据内部维护的一个优先列表来决定，这个优先列表记录了回收可以获得空间大小以及回收空间所需要的时间的经验值，同时还维护了一个 Remembered Set 来记录当前的 Region 的引用关系。

#### 新生代 GC

##### Serial 收集器

Serial 收集器回收新生代内存对象，是最古老的一种收集器，它在 Jdk 1.3.1 之前是新生代唯一的新生代收集器

Serial 在新生代采用复制算法

Serial 收集器是单线程的，也就是说 Serial 收集器执行的时候，只能是一个 CPU 或者 线程来执行垃圾收集过程，所以在 Serial 工作期间，会发生 Stop the world，也就是停止该程序的所有其它操作，也就是程序无响应

Serial 的优点在于，由于没有线程交互的开销，所以相对于其它的垃圾收集器简单而高效，在单个 CPU 的环境可以获得最高的单线程收集效率

Serial 适用于 Client 客户端的开发

可以配合 CMS & Serial Old 老年代垃圾收集器一起工作

##### ParNew 收集器

ParNew 负责回收新生代内存中的对象，采用复制算法

ParNew 是 Serial 收集器的多线程版本，除了并行(指的是多个垃圾回收线程并行执行，不过同样要暂停用户线程)的特性外，其余都一致

在单 CPU 的条件下，回收效率没有 Serial 高，但是在并发情况下效果更好

ParNew 用于 Server 端，是唯一款可以和 CMS 搭配的适用于 Server 新生代收集器

可以配合 CMS & SerialOld 老年代收集器一起工作

##### Parallel Scavenge 收集器

ParNew 负责回收新生代内存中的对象，采用复制算法

ParNew 是 Serial 收集器的多线程版本，除了并行(指的是多个垃圾回收线程并行执行，不过同样要暂停用户线程)的特性外，其余都一致

在单 CPU 的条件下，回收效率没有 Serial 高，但是在并发情况下效果更好

ParNew 用于 Server 端，是唯一款可以和 CMS 搭配的适用于 Server 新生代收集器

可以配合 CMS & SerialOld 老年代收集器一起工作

#### 老年代

##### CMS 收集器

CMS 属于老年代垃圾回收器，采用标记 - 清除算法

CMS 的目标是尽可能的减少回收停顿时间，从而提高用户的响应时间和体验度

CMS 是一款并发的垃圾收集器，在它的并发标记与并发清除阶段，不需要暂停用户线程

CMS 工作分作四个步骤

1. 初始标记(Stop the world) 只需要简单标记一下 GC Root 能直接关联到的对象
2. 并发标记
3. 重新标记(Stop the world)
4. 并发清除
   其中时间开销 T(并发标记) > T(重新标记) > T(初始标记)

由于整个过程中耗时最长的并发标记阶段和并发清除阶段过程，垃圾收集器都可以与用户线程一起工作，所以总体上来讲 CMS 收集器的回收过程是和用户线程并发工作的

缺点有三点

1. CMS 对 CPU 资源敏感，因为与用户线程一起工作，所以会抢占用户线程的 CPU 资源，导致用户线程的执行效率下降
2. CMS 无法收集浮动垃圾，可能会导致 Concurrent Mode Failure 失败而导致另一次 Full GC 的产生. 浮动垃圾是当垃圾回收器在运行的适合产生的新的垃圾. Concurrent Mode Failure 是当 CMS 运行期间，预留给用户的内存不够，这是 JVM 会启动备用方案: 使用 Serial Old 垃圾收集器来回收老年代，这个适合就需要 Stop the world，所以预留给用户的内存比例不能太小
3. CMS 基于标记 - 清除算法实现的，所以会产生很多空间碎片

CMS 适用于 Server 端，需要重视服务的响应速度，系统停顿时间最短的应用

CMS 可以搭配 Serial & ParNew 年轻代垃圾回收器一起工作

##### Serial Old 收集器

Serial Old 负责回收老年代内存当中的对象，采用标记 - 整理算法

Serial Old 适合于 Client 客户端，但在 Server 端也有两大用处

1. 在 JDK 1.5版本之前搭配 Pallel Scavenge 收集器使用
2. 当 CMS 并发收集发生 Concurrent Mode Failure 的适合，作为备用方案

可以配合 Serial & ParNew & Parallel Scavenge 年轻代收集器一起工作

##### Parallel Old 收集器

Parallel Old 负责老年代的对象回收，采用标记 - 整理的算法

Parallel Old 是 Parallel Scavenge 的老年代收集器，同样关注高吞吐量

只能配合 Parallel Scavenge 完成工作，针对交互少，需要大量计算的任务

### 什么时候触发 GC

由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC 和 Full GC。

#### Scavenge GC

一般情况下，当新对象生成，并且在 Eden 申请空间失败时，就会触发 Scavenge GC，对 Eden 区域进行 GC，清除非存活对象，并且把尚且存活的对象移动到 Survivor 区。然后整理 Survivor 的两个区。这种方式的 GC 是对年轻代的 Eden 区进行，不会影响到年老代。

#### Full GC

对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个对进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。

触发 full GC

1. 年老代（Tenured）被写满
2. 持久代（Perm）被写满
3. System.gc()被显示调用
4. 垃圾收集器自定义的策略被激活

### 什么情况下影响新生代回收速度

1. Eden 与 Survivor 分区大小的比例，当 Survivor 很小的时候，可能会频繁的引起新生代的回收

2. 较大的 Eden 与 Surviror 也会影响到新生代回收需要扫描的对象的数量

## 类加载

### 类加载过程

类加载由 5 个阶段的动作组成：加载、验证、准备、解析、初始化

1. 加载

主要做三件事情：1.获取一个类的二进制字节流。2.把这个字节流的数据转化成运行时数据结构。3.在内存当中生成一个代表这个类的 Class 对象，用于方法区对这个类的各种数据的访问入口

不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），
也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。

2. 验证

验证主要是为了保证 Class 文件字节流当中的信息是符合 JVM 要求的不会危害 JVM 自身安全的。也就是要检查是否访问数组边界以外的数据、强制转换了一个不存在的类等等

3. 准备

准备阶段是为 类变量 分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。

注意 `public static int value = 123` 在这个阶段初始化后为 0 而不是 123，123 是在编译阶段 putstatic 指令被运行的时候才赋值

4. 解析

解析是把 JVM 常量池当中的符号引用替换为直接引用的过程

符号引用：符号引用以一组符号来描述锁引用的目标，可以是任何形式的字面量，只要能无歧义的定位到一个目标即可

直接引用：直接引用是直接指向目标的指针或者句柄

5. 初始化

初始化是真正的执行类当中定义的 java 程序代码

在准备阶段，变量已经按照系统的要求赋值过一次，但是在初始化阶段，可以通过程序指定计划去初始化类变量和其它资源

注意以下几种情况不会执行类初始化：

1. 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。
2. 定义对象数组，不会触发该类的初始化。
3. 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。
4. 通过类名获取Class对象，不会触发类的初始化。
5. 通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。
6. 通过ClassLoader默认的loadClass方法，也不会触发初始化动作。

### 类加载时机

JVM 当中没有明确规定什么时候执行加载过程，只规定了五种情况必须要初始化

1. 遇到 new getstatic putstatic invokestatic 字节码是，如果没有初始化，一定要初始化

也就是当 new 关键字示例化对象的时候，读取或者设置一个类的静态字段的时候以及调用一个类的静态方法的时候

2. 使用 reflect 反射机制的时候，如果类没有进行过初始化，则先触发其初始化

3. 当初始化一个类的时候，如果其父类还没有初始化，要先初始化它的父类

4. 虚拟机启动的时候，初始化 main 方法的类

### 双亲委派模型

双亲委派模型的工作过程是，如果一个类加载其收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求给它的父类去实现，每一个层次的类加载器都是如此，只有当父类加载器反馈自己无法完成这个加载请求的时候，子加载器才会自己去加载。

好处：Java 类随着它的类加载器一起具备了一种层次关系，例如 Object，无论任何一个加载器来加载都应该是启动类加载器来加载，而不是由不同的加载器来加载，如果由不同的加载起来加载就会产生很多个不同的 Object 类(不同的类加载器加载同一个类不认为是相同的类)

# MySQL

## 事务

### 什么是事务

事务是一系列 Sql 操作，也可以叫做一个独立的工作单元，该工作单元封装了一系列的工作流程，该流程当中的每个步骤都必须要全部成功，如果有一个步骤失败，则整个工作流程都算失败。

### 事务举例

假设一个银行的数据库当中有两张表，**支票(checking)表** & **储蓄(caving)表**，现在要从用户 Jane 的支票表当中转移 200 美元到他的储蓄账户当中，那么事务处理的步骤至少应该做这些事情

1. 检查支票账户的余额，如果低于 200 那么这个步骤失败
2. 从支票账户当中减去 200 美元
3. 在储蓄账户当中增加 200 美元

以上的三个步骤组合起来叫做 **事务**，任何一个步骤失败，则必须回滚所有的步骤。

### 事务的4个特性

事务有4个特性：原子性、隔离性、持久性、一致性。

### 原子性

在我们操作数据库的时候，事务是做一个不可分割的最小的工作单元，整个事务的所有步骤，要么全部成功，要们就全部失败，不可能只执行其中的某一部分操作。

### 隔离性

通常来讲，一个事务所做的修改，在最终提交前，对其他的事务都是不可见的。

### 持久性

一旦事务提交，那么所做的修改就会永远的保存在数据库当中。

### 一致性

执行业务操作的时候，会预先规定一些规定，在进行事务的时候，必须要从一个满足这些规定的状态到另外一个满足这个状态中去，
例如规定转账的时候支票账户和储蓄账户相加的总数要为原来的事务开始时候的状态，同时按照预先规定的流程执行事务，事务执行完后，同样要满足预先设定的业务规定。

## 隔离级别

Sql 标准当中定义了 4 种隔离级别，分别是 **未提交读(Read committed)** **提交读/不可重复读(Read Committed)** **可重复度(Repeateable Read)** **可串行化**

隔离级别规定了一个事务当中所做的修改对于系统当中的其它 session 的可见程度的高低

大部分的数据库默认级别是 **Read Committed**，mysql 当中的默认级别是 **Repeateable Read**

ps: 在数据库当中执行 ```select @@session.tx_isolation;``` 可以查询 **事务的隔离级别**，在数据库当中执行 ```set session transaction isolation level serializable;``` 可以更改数据库隔离级别，但是时间只是在这次 client 打开的时候，当再次登录时，隔离级别会重置

#### 未提交读

事务当中的修改，即使没有提交，其它事务能看见这个事务当中的修改操作

这个级别当中不经不能保证事务的一致性，而且本身能够得到的性能优化也非常的有限

##### 案例

例如有两个 session 分别为 session A & session B，还有一个表 **status(id int，number id)**

实验步骤为：打开两个事务 -> 事务 A 插入数据 **id = 1 & number = 10** 并且不提交 -> 在事务 B 当中查询 **id = 1** 可以查到该插入记录

打开两个事务，在 client A 当中执行 ```start transaction```，在 client B 当中执行 ```start transaction```

client A 当中执行代码 ```insert into status (id，number) values (1，10)``` 插入数据，在 client B 当中执行查询 ```select id，number from status where id = 1;```

按照事务隔离等级的规则，事务 B 在事务 A 提交之前或提交之后都可以查看到 session A 插入的结果

#### 提交读/不可重复读

提交读的意思是，当一个事务当中执行操作，只有当当前的这个事务提交之后，别的事务才能看到这个事务执行后的数据更新效果。

提交读又叫做不可重复度，不可重复读的意识是可能会在读取当中由于另外事务 session A 提交了数据的更改操作，导致没有办法再读取到 session A 提交之前的数据。

###### 案例

例如有两个 session 分别为 session A & session B，还有一个表 **status(id int，number id)**

实验步骤：打开两个事务 -> 事务 A 插入数据 **id = 2 && number = 20** -> 事务 B 执行查询 -> 事务 A 提交事务 -> 事务 B 执行查询

打开两个事务，在 client A 当中执行 ```start transaction;```，在 client B 当中执行 ```start transaction;```

client A 当中执行代码 ```insert into status (id，number) values (2，20)``` 插入数据，在 client B 当中执行查询 ```select id，number from status where id = 2;``` 再在 client A 当中提交事务 ```commit;```，当事务 A 提交过后在 client B 当中再次执行查询 ```select id，number from status where id = 2;```

按照事务隔离等级的规则，事务 B 无法查看到事务 A 执行 ```commit;``` 命令之前的插入数据，但是在事务 A 执行完提交语句后 ```commit;```，事务 B 可以查询到事务 A 执行的插入语句

#### 可重复读

可重复读的意思是，一个事务如果打开了，那么就算别的事务提交了对数据的修改，这个事务依旧可以读取到打开时事务的数据，直到它本身提交后，才会读取到新的被别的事务修改过后的数据。

##### 案例

例如有两个 session 分别为 session A & session B，还有一个表 **status(id int，number id)**

实验步骤: 打开两个事务 -> 事务 A 插入数据 **id = 3 & number =30** -> 事务 B 执行查询 -> 事务 A 提交事务 -> 事务 B 再次执行查询

打开两个事务，在 client A 当中执行 ```start transaction;```，在 client B 当中执行 ```start transaction;```

client A 当中执行代码 ```inser into status (id，number) values (3，30)``` 插入数据，在 client B 当中执行查询 ```select id，number from status where id = 3``` 再在 client A 当中提交事务 ```commit;```，当事务 A 提交过后在 client B 当中再次执行查询 ```select id，number from status where id = 3```

按照事务隔离等级的规则，事务 B 无法查看到事务 A 插入的数据，即使事务A 提交了事务，事务 B 也没有办法查看到事务 A 插入的数据.

#### 可串行化

最高的隔离级别

可序列化的意思是，数据库在同步控制当中，强制的在同一时间内只能有一个事务进行读或取操作(具体看锁的类型)，也就是说当多个事务对同一数据进行操作的时候，需要去获取锁才可以

实验步骤: 打开两个事务 -> 事务 A 执行插入语句 ```insert into status (id，number) values (4，40)``` -> 事务 B 执行查询 -> 事务 A 更新数据 ```update status set number = 44 where id = 4;``` -> 事务 B 执行更新语句 ```update status set number = 444 where id = 4;```

按照事务隔离等级的规则，事务 B 的更新语句无法执行，只有当事务 A 提交了事务后，事务 B 的更新语句才能执行

#### 隔离级别的读问题

这里说的读问题，指的是不同的隔离级别的条件下，许多个事务同时执行读写操作的时候，会产生的一些问题，所以读问题都是建立在事务隔离级别之下来讨论的

一般来讲会有三种读问题: **脏读** **不可重复读** **幻读**

事务的隔离等级和读问题的关系

| 隔离级别 | 脏读可能性 | 不可重复读可能性 | 幻读可能性 | 加锁读 |
| -------- | ---------- | ---------------- | ---------- | ------ |
| 未提交读 | yes        | yes              | yes        | no     |
| 提交读   | no         | yes              | yes        | no     |
| 重复读   | no         | no               | yes        | no     |
| 可串行化 | no         | no               | no         | yes    |

##### 脏读

脏读又叫做无效数据读出

脏读指的是在数据访问当中，事务 T1 将某一值进行修改但是还没有提交，存在事务 T2 读取该数据 && 可以读取到 T1 修改但是没有提交的值，然后 T1 运行时有步骤失败需要回滚事务，这个时候事务 T2 读取到的值就是脏数据，依照脏数据所做的操作可能是不正确的

脏读一般发生在: 多个事务的内部修改对其他事务来讲是可见的。

##### 不可重复读

不可重复读指的是，假设事务 T1 第一次读取某一数据结果集为 set A，在事务 T1 读取完后，有第二个事务 T2 读取并且了该数据然后提交事务，事务 T1 再次执行与第一次读取相同的代码再次得到一个结果集 set B，这个时候，set A 当中的数据和 set B 当中的数据不一致，也就是在别人修改并且提交事务后，T1 没有办法再读取到和第一次读取时相同的数据集，就叫做不可重复读

不可重复读是由于事务的交叉提交而导致的

##### 幻读

幻读是建立在解决了不可重复读的问题之上的，解决不可重复读是让这个事务在执行的时候，所有的读取操作都是事务开始的时候的一个状态，所以在执行操作完成后再次执行相同的查询就会产生不同的结果集，这样就会导致如果我的操作是根据结果集的内容来做修改或者判断的依据，那么当别的事务提交新的数据的时候，在执行操作的这个业务不会感知到，从而导致有一部分数据就像是幻觉一样

## 事务的实现

#### undo log

undo 日志用于存放数据被修改前的值。

假设修改 a 表中 id=2 的行数据，把 Name='B' 修改为 Name = 'A' ，那么 undo 日志就会用来存放 Name='B' 的记录，如果这个修改出现异常，可以使用 undo 日志来实现回滚操作，保证事务的一致性。

undo log 是逻辑日志，根据每行的记录进行记录，恢复事务对数据库数据的修改。

#### redo log

insert 一条记录时，插入的信息都会放进 redo 中，在  commit 之前，redo 的信息会放进硬盘上。故障时，redo 便可恢复那些已经 commit 了的数据。

每次操作都先记录到 redo 日志中，当出现实例故障（像断电），导致数据未能更新到数据文件，则数据库重启时须redo，重新把数据更新到数据文件。

redo log 有一个很特别的地方，就是 Redo log 以顺序的方式写入文件文件，写满时则回溯到第一个文件进行覆盖重写。

redo log 是物理日志，记录的是物理的修改记录，由于特殊原因数据丢失需要恢复数据库之前的数据。

#### undo log 与 redo log 的 IO 影响

Undo 搭配 Redo 的设计主要考虑的是提升 IO 性能，增大数据库吞吐量。只有当事务要提交之前才会进行 IO 操作，之前的更新操作都是写到 redo 的缓冲区当中，这样就保证 Redo Log 能够有比较好的 IO 性能，InnoDB 的 Redo Log 的设计有以下几个特点：

A. Redo Log 存储在一段连续的空间上。因此在系统第一次启动时就会将日志文件的空间完全分配。 以顺序追加的方式记录 Redo Log，这样可以减少硬盘指针寻址的时间。

B. 批量写入日志。日志并不是直接写入文件，而是先写入 redo log buffer。当需要将日志刷新到磁盘时(如事务提交)，再将缓冲区的日志一起写入磁盘。

C. 并发的事务共享 Redo Log 的存储空间，它们的 Redo Log 按语句的执行顺序，依次交替的记录在一起，以减少日志占用的空间。例如，Redo Log中的记录内容可能是这样的：
     记录1: <trx1，insert …>
     记录2: <trx2，update …>
     记录3: <trx1，delete …>
     记录4: <trx3，update …>
     记录5: <trx2，insert …>

D. 因为多个事务同时都可以写入 Redo log 的原因，当一个事务将 Redo Log 写入磁盘时，也会将其他未提交的事务的日志写入磁盘。

E. Redo Log上只进行顺序追加的操作，当一个事务需要回滚时，它的 Redo Log 记录也不会从 Redo Log 中删除掉。

#### undo log 与 redo log 与数据恢复

MySQL 数据库 InnoDB 存储引擎使用的策略是这样的：进行恢复时，重做所有事务包括未提交的事务和回滚了的事务。然后通过 Undo Log 回滚那些 未提交的事务。

InnoDB 存储引擎中的恢复机制有几个特点：

A. 在重做 Redo Log 时，并不关心事务性。 恢复时，没有 BEGIN，也没有 COMMIT，ROLLBACK 的行为。也不关心每个日志是哪个事务的。尽管事务 ID 等事务相关的内容会记入 Redo Log，这些内容只是被当作要操作的数据的一部分。

B. 使用B策略就必须要将Undo Log持久化，而且必须要在写Redo Log之前将对应的Undo Log写入磁盘。Undo和Redo Log的这种关联，使得持久化变得复杂起来。为了降低复杂度，InnoDB将Undo Log看作数据，因此记录Undo Log的操作也会记录到redo log中。这样undo log就可以象数据一样缓存起来，而不用在redo log之前写入磁盘了。

包含Undo Log操作的Redo Log，看起来是这样的：
    记录1: <trx1，Undo log insert <undo_insert …>>
    记录2: <trx1，insert …>
    记录3: <trx2，Undo log insert <undo_update …>>
    记录4: <trx2，update …>
    记录5: <trx3，Undo log insert <undo_delete …>>
    记录6: <trx3，delete …>

C. 因为 Redo 没有事务性，所以会重新执行被回滚了的事务，同时 Innodb 也会将事务回滚时的操作也记录到 redo log 中。因为回滚操作本质上也是对数据进行修改，因此回滚时对数据的操作也会记录到 Redo Log 中。

一个回滚了的事务的 Redo Log，看起来是这样的：
    记录1: <trx1，Undo log insert <undo_insert …>>
    记录2: <trx1，insert A…>
    记录3: <trx1，Undo log insert <undo_update …>>
    记录4: <trx1，update B…>
    记录5: <trx1，Undo log insert <undo_delete …>>
    记录6: <trx1，delete C…>
    记录7: <trx1，insert C>
    记录8: <trx1，update B to old value>
    记录9: <trx1，delete A>

*！* 一个被回滚了的事务在恢复时的操作就是先redo再undo，因此不会破坏数据的一致性。

#### 原子性的实现

回滚日志来实现。

数据库当中的事务在执行的时候，事务对数据的修改都会记录相反的操作到 undo log 日志当中同时会记录修改的记录到 redo log 日志当中，如果事务需要回滚，那么就会依照这个修改日志来回滚，如果没有问题，就会对数据对应的行进行写入操作。

#### 隔离性的实现

隔离性的实现依赖于数据库的并发控制，我所了解到的并发控制有两种: **锁** **多版本/快照隔离**

#### 一致性的实现

使用 redo log 来实现，当事务没有完整提交的时候，可以通过 redo log 来重写的。

#### 持久性的实现

根据数据库的 redo log 来保障的，redo log 可以在数据库崩溃的时候恢复数据库当中的数据。

存储引擎

#### InnoDB

Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别。该引擎还提供了行级锁，它的设计目标是处理大容量数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，
用于缓冲数据和索引。但是有一个小细节是，它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。
由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。

#### MyISAM 

MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。
不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。
所以，如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。

#### 应用场景

1. MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM
2. InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB

## 索引

#### 什么是索引

索引是一个类似与目录的东西，它能够指明所需要查找的数据的位置。

#### 索引的优点

索引的具体功能是基于其实现方式的数据结构的特性，例如 B-Tree 当中的数据是有序的，那么基于 B-Tree 的索引就具有排序快这一优点，但具体有三点

- 大大减少服务器需要扫描的数据量
- 帮助服务器避免排序和临时表
- 将随机 I/O 变成顺序 I/O

#### 索引的工作原理

索引类似于书本的目录，想要找到一个特定的数据时候，一般先回去找到这个索引存放的指向具体数据的指针，再返回想要找到的数据。

#### 哈希索引

哈希索引是基于哈希表实现的，对与每一行数据，存储引擎都会对所有的索引列计算一个哈希码，不同的哈希码也不一样，哈希索引将所有的哈希码存储在索引当中，同时也创建一个哈希表，在这个哈希表当中保存指向每个数据行的指针，它适合于精确匹配查找，与 B-Tree 不同的是非常的快

Mysql 当中，只有 Memory 引擎现实支持哈希索引，Memory 引擎也是默认把哈希索引当中索引类型

##### 哈希的有效查询

精确匹配索引的所有列的查询

##### 限制

- 必须要整个索引键才能唯一确定一行
- 没有办法提高 ORDER BY 操作
- 哈希索引一定会读取数据行，因为哈希索引只保存了哈希值和行指针，不会保存字段值
- 哈希索引并不按照索引值顺序存储的，索引也就无法用于排序
- 哈希索引是把所有的索引列都用来计算才能得到唯一的哈希值，所以也就没有办法使用部分索引列匹配查询
- 哈希索引只支持等值比较查询，不能做范围查询
- 如果哈希冲突很高的话，那么就需要遍历所有这个索引值可能生成的哈希值

##### InnoDB 使用哈希索引的优化

InnoDB 的索引使用 B-Tree 来实现，但是如果引擎发现某一个索引值会被频繁的访问到，那么就会计算它的哈希码，然后基于 B-Tree 的数据结构生成一个哈希索引，这样就具备了一些哈希的基本优点

例如: 当有一个表存放了一些关于网页的信息`id，url，name，context`，使用 B-Tree 的查找方法一般为 `select id from table where url='http://www.mysql.com'`，如果这个时候表很大查找起来就会很慢，这个时候如果新加入一列 url 的哈希码使表变成 `id，url ，name ，context，hash`，并且使用这个查找方法`select id from table where url='http://www.mysql.com' and hash=CRC32('http://www.mysql.com')`，那么引擎会优先根据选择性很高而且体积很小的一列也就是 **hash** 这一列来查找，这个时候就会得到一些索引条目，然后一一比较返回对应的行，就可以得到内容

*!* CRC32() 返回32位整数，当索引条目为 93000 条记录的时候，出现冲突的概率为 1%

#### B-Tree 索引

B-Tree 常用来实现 **数据库** 和 **文件系统** 的一个数据结构，它能保持数据的有序性，很适合用来查找范围类型的数据

##### B-Tree 工作原理

例如有一颗 **m 阶 B-Tree** 从根结点开始插入数据，每一节点当中保存 **键值** **指针** **数据** 三种类型的数据，**键值** 就是数据库当中的索引数据，**指针** 指向的该节点的孩子，**数据** 则是指向数据存放地址的一个句柄，每一个节点最多只能有 m 个孩子，并且在插入的时候对比当前的键值的大小决定是否在当前的节点插入或者插入该节点的那个孩子，如果是查询，就会从根结点开始，同样是对比范围，然后确定查找的范围，最后要么查找到该数据，要么就是空值

##### 有效查询

B—Tree 索引适用于全键值、键值范围、最左前缀查找

- 全值匹配 和索引中的所有的列进行匹配
- 匹配最左前缀 匹配索引当中的第一列数据
- 匹配列前缀 只匹配某一列的值的开头部分，例如 J 开头的姓的人
- 匹配范围值 查找某个范围内的值
- 精确匹配某一列并范围匹配另外一列 例如查找所有姓为 Allen，并且名字为字母 K 开头的人
- 只访问索引的查询 查询的过程值需要防伪索引，而无需访问数据行

##### 限制

- 如果不是从最左边的列开始查找，则无法使用索引
- 不能跳过索引中列，也就是匹配的过程要按照索引定义的列的顺序来匹配
- 在一个索引集合当中，其中一个查询有某个列的范围查询，则这个列右边的所有的列都无法使用索引优化技术

##### 特性

1. 每个节点最多有m个孩子。
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
3. 若根节点不是叶子节点，则至少有2个孩子
4. 所有叶子节点都在同一层，且不包含其它关键字信息
5. 每个非终端节点包含n个关键字信息（P0，P1，…Pn，k1，…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
7. ki(i=1，…n)为关键字，且关键字升序排序。
8. Pi(i=1，…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

#### 唯一索引

唯一索引所在的列的所有的值都不能被重复

系统在创建该索引时检查是否有重复的键值，并在每次使用 INSERT 或 UPDATE 语句添加数据时进行检查。

##### 书写方法

```sql
CREATE UNIQUE CLUSTERED INDEX myclumn_cindex ON mytable(mycolumn)
```

CLUSTERED INDEX是用来建立聚簇索引的关键字。

此语句的意思是在表mytable上的mycolumn字段上创建一个名为myclumn_cindex的聚簇索引，且为唯一索引。

#### 索引优化

##### 独立的列

在使用 where 语句的时候，`=` 号前边的索引不能有运算符或者是作为函数的参数，不然 sql 语句没有办法解析，也就没有办法使用索引

例如: `select id from actor where id + 1 = 5;` 这个时候就没有办法解析 `id + 1 = 5`，应该改成 `select id from actor where id = 4;`

##### 前缀索引

当需要对类似于 text 或者很长的 varchar 这样的大文本建立索引的时候，如果不做处理就建立索引，就会让索引变得很大而且很慢而且 mysql 也不支持索引这些列的完整长度，前缀索引就是把这一列的前面一部分数据当作索引，例如一篇文章的开始的 10 个字当作这一行的索引数据，选择多长的数据当作索引，同时需要考虑效率和索引的选择性

*!* 索引的选择性指的是 **不重复的索引值**/**数据表的记录总数**，选择性越高效率就越高，因为选择性高的索引可以让 mysql 在查找的时候过滤掉更多的行

*!* 唯一的索引的选择性为1

*!* 一般来讲，前缀长度的大小取决于 **最常出现的前缀的出现次数** 与 **最常出现的索引行数据的次数** 相当或者再加 1 选择性的提升不大

##### 多列索引

如果在一张表里面需要利用多个列来搜寻唯一一行数据，那么我们有三个方法 **全表扫描** **建立多个单列索引** **建立一个多列索引**

**全表扫描** 的缺点是效率不高

**建立多个单列索引** 在使用多个单列索引查找的时候，会有一个索引合并的操作，mysql 可以把它换做成 OR 条件 & AND 条件 & OR 和 AND 条件的合并，但是由于需要对每一个列都建立索引，那么就会使得索引膨胀很快

**建立多列索引** 多列索引把多个列建立成索引，建立多个索引的查询是根据索引定义的第一个列开始查找，然后当第一个列的值相同的时候，就比较第二列的值，以这样的方式来查找到数据，当我们建立了 (A，B，C) 索引的时候相当于建立了 (A，B，C) & (A，B) & (A) 三个索引

###### 多列索引的顺序

建立多列索引需要考虑到索引列的顺序问题，需要通过 **具体的场景** + **索引的选择性** + **全局基数** 来衡量

**具体的场景** 指的是索引应该考虑到的例如 **排序** **分组** 这样的特殊情况，例如当我们使用 B-Tree 当作索引的时候，它的排序是先匹配第一列再匹配第二列，所以这个时候，列的顺序就很重要了，这直接影响到排序的结果

**索引的选择性** 指的是我们在不考虑具体场景的情况下，应该把选择性高的一列放在索引当中的前面些的位置，因为这样的话，能够最快的过滤出所需要的行，同时对于在 where 子句当中只是用了索引部分的前缀列的查询来说选择性也更高

**全局基数** 指的是当一个索引存在特殊值，根据这个特殊值查询到的结果集很大时，就需要对这个索引做特殊的处理

##### 覆盖索引

是指如果查询的列恰好是索引的一部分，那么查询只需要在索引文件上进行，不需要回行到磁盘再找数据，这种查询速度非常快，这个现象称为“索引覆盖”。

- 极大减少查询数据对磁盘的访问次数

- 如果二级主键能够覆盖查询，可以避免回表操作

##### 聚簇索引

聚簇索引是按照索引顺序把数据行存储在磁盘上的一种索引，这样做有几个好处 1.优化范围查询(因为它把相邻的数据存放在一起了) 2.有一个默认的顺序

- 索引的顺序按照主键的顺序来规定
- 聚簇索引不是作为数据库当中的一个单独的对象/结构存在，换一种话来说，聚簇索引实际是一个表
- 聚簇索引当中的索引叶不仅仅存放 **索引键** 它还会存储整个行数据

好处：聚簇索引通常要比非聚簇索引快，因为它在索引表当中存储了数据，比起非聚簇索引它会少一个 I/O 操作

限制：由于聚簇索引按照一定的规则对数据进行了排序，那么在每次 **插入** 与 **删除** 的时候都需要对树当中的位置进行调整

- 插入: 插入的效率依赖与插入的顺序，按照主键的顺序来插入是最快的
- 删除: 删除可能会导致下方的数据向上移动来填充删除掉的数据产生的空白位置，这样会有大量的移动操作
- 更新: 当更新主键的时候，会重新的调整主键的位置，所以一般不会更新主键

##### 压缩索引

MyISAM 使用前缀压缩来减少索引的大小，一般只默认压缩字符串，但也可以压缩数字，压缩每个索引块的方法是，先完全保存索引块当中的第一个值，然后其它值和第一个值进行比较，得到一个相同的前缀和一个不同的后缀，然后在用前缀和后缀替换掉原来的数据

例如: 索引块当中第一个值是 `perform` 第二个值是 `performance`，那么第二个值压缩过后就是 `7，ance`

压缩索引可以让索引所占的空间变得很小，但是会降低查询的速度，尤其是在 **随机查询** 和 **高密度 I/O** 的应用当中

##### 减少冗余、重复、未使用的列

减少冗余、重复、未使用的列

## 并发控制

#### 什么是并发控制

并发控制主要是为了保障事务当中的 **隔离性** 而存在的，控制并发的方式有两种: 1.使用锁 2.使用版本控制

关于锁，mysql 对于锁的分类有很多种方式: **按照处理并发的策略叫做: 悲观锁 & 乐观锁** **按照锁的粒度来分: 表锁 & 页锁 & 行锁**

关于版本控制有两种实现方式 **系统版本号 & 时间戳**

#### 锁

##### 锁的分类

按粒度来分：表锁 & 页锁 & 行锁

按策略来分：悲观锁 & 乐观锁

##### 粒度锁

###### 各存储引擎的支持

- MyISAM & MEMORY 支持 **表级锁**
- BDB 支持 **页面锁( 默认 )** **表级锁**
- InnoDB 支持 **行级锁( 默认 )** **表级锁**

###### 锁的优劣

- 表级锁: 开销大，加锁快; 不会出现死锁; 锁定粒度大，发生锁冲突的概率最高，并发程度最低
- 行级锁: 开销大，加锁慢; 会出现死锁; 锁定粒度最小，发生锁冲突的概率最低，并发读页最高
- 页面锁: 开销和加锁时间介于表锁和行锁之间; 会出现死锁; 锁定粒度介于表锁和行锁之间，并发度一般

###### MyISAM 表级锁

MyISAM 只支持表级锁，所以在这个存储引擎当中表级锁有两个工作模式 **表共享锁 & 表独立锁**

当一个事务想要对表进行读操作的时候，就会获得一个读锁，读锁是共享的，读锁和读锁之间不会相互排斥，执行 **SELECT** 语句的时候会自动给涉及的表加 **读锁**

当一个事务想要对表进行写操作的时候，就会要求获得一个写锁，写锁是独占的，会阻塞其它事务获取读锁和写作，同时也会阻塞其它事务的读写操作，执行 **UPDATE** **DELETE** **INSERT** 语句的时候会自动给涉及的表加 **写锁**

###### MyISAM 表级锁的调度

MyISAM 认为 **写操作** 比 **读操作** 更加重要

如果两个事务同时分别请求一个读锁和一个写锁，那么优先分配该表的写锁给写锁事务

所以 MyISAM 更适合读操作比较密集 & 写操作比较少的表，因为如果存在大量的写操作，那么写会优先获得锁，那么读操作就很难获得读锁，从而可能永远阻塞

*！* 在长时间调节读写优先级的时候应该注意: 长时间的 **读进程** 可能会导致 **写进程** 饿死，**长时间** 的写进程可能也会导致 **读进程** 永远阻塞

###### MyISAM 的并发插入

并发插入是为了解决读和插入写操作串行执行导致效率过低的问题，所以 Mysql 提供一个系统变量 **concurrent_insert** 来控制在什么样的条件下，允许在表的末尾插入的数据

比如一个 session 获取了 demo 表的 READ LOCAL 锁，该线程可以对表进行查询炒作，但不能对表进行更新操作，如果我们允许插入的话，其它的线程就可以根据 **concurrent_insert** 变量的值来对 demo 表进行并发插入操作

###### MyISAM 表级锁兼容性

```
//是否兼容
     | None | 读锁  | 写锁  |
读锁  |  是   |  是  |  否  |
写锁  |  是   |  否  |  否  |
```
###### InnoDB 锁支持

InnoDB 支持 **行级锁** **表级锁** ，但是 **行级锁** 是默认采用的

InnoDB 和 MyISAM 的主要区别 **InnoDB 支持事务** **InnoDB 采用了行级锁**

###### InnoDB 锁分类

两种行锁

- 共享锁 S
- 排他锁 X

*！* 对于 UPDATE & DELETE & INSERT，InnoDB 会自动给设计的数据集加 **排他锁(X)**
*！* 对于普通的 SELECT 语句，InnoDB 不会加任何、

两种内部使用的意向锁 && 表锁

- 意向共享锁 IS (事务打算给数据行加行共享锁，那如果想给一个数据行加共享锁钱必须先取得该表的 IS 锁)
- 意向排他锁 IX (事务打算给数据行加行排他锁，那如果想给一个数据行加排他锁就必须先取得该表的 IX 锁)

*！* 意向锁都是 InnoDB 自动加的，不需要用户干预

###### InnoDB 行锁兼容性

```
    //是否兼容，能同时获取到锁并操作表
       |  X  |  IX  |  S  |  IS  |
    X  |  N  |  N   |  N  |   N  |  
    IX |  N  |  Y   |  N  |   Y  |  
    S  |  N  |  N   |  Y  |   Y  |  
    IS |  N  |  Y   |  Y  |   Y  |  

```

###### InnoDB 行锁的实现

InnoDB 的行锁是通过给索引上锁来实现的，具体分为 **有索引**  **无索引**

- **有索引** 给索引上锁
- **无索引** 通过隐藏的聚簇索引来对记录加锁

###### InnoDB 行锁的三种情况

- Record Lock 对索引项上锁，所以说当一条sql没有走任何索引时，那么将会在每一条聚集索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。
- Gap Lock 对索引项之间的'间隙' & 第一条记录前的'记录' & 最后一条记录后的‘间隙’ 加锁
- Next-key Lock 前两种的组合，对记录和前面的'间隙' 上锁

*！* 间隙: 值得是通过一个条件范围获取一堆数据，数据库当中没有的数据但是却数据条件范围内的就叫做间隙. 例如: `select * from emp where emp_id > 100 for update` 如果数据库当中有 **1-101** 的数据项，那么 **102** 就属于间隙，间隙存在是为了防止幻读

##### 策略锁

###### 悲观锁

悲观锁是以加锁的方式来独占一个数据资源，从而防止另外的事务在该事务更新或者操作数据的时候改变了数据的状态

数据安全性高、并发效率低

###### 悲观锁的处理流程

1. 线程读取某条数据
2. 线程立刻尝试给该数据上锁
3. 等待获取该数据的锁的权限
4. 加锁成功后，对数据进行操作
5. 操作完毕，提交事务，释放锁资源

###### 乐观锁

乐观锁认为数据操作处于一种无竞争或者少量竞争的情况，所以在乐观锁策略不使用锁来处理并发，而是利用 **系统版本号** 或者 **时间戳** 来控制并发，它首先获取数据和数据当中的版本控制标识，然后认为是没有事务与其竞争这个数据资源，对这个数据资源直接进行处理，然后在提交事务的时候再对比版本标识，如果所持有的版本标识在时间维度上低于数据库当中的版本标识就意味着这个事务在处理这个数据的时候有另外的事务已经处理并且提交了对当前数据的处理，那么这个时候事务就需要放弃操作并且回滚

一般用 **系统版本号** 或者 **时间戳** 来实现

数据安全低、并发效率高

###### 乐观锁的处理流程

1. 线程读取记录和版本号
2. 更新记录
3. 对比当前数据库当中的该记录的版本号和已读取的版本号
4. 如果两个版本号在时间维度上是一致的，则提交更新并且版本号 + 1，否则回滚

###### 悲观锁与乐观锁

**悲观并发控制** 和 **乐观并发控制** 又分别叫做 **悲观锁** 和 **乐观锁** 所以乐观锁和悲观锁不是 mysql 当中锁的分类，而是处理并发的一种 **策略** 或者一种 **态度**

#### 多版本控制

##### 什么是多版本控制

多版本控制是为了提升并发的性能，在很多情况下避免了加锁的操作，因此和锁对比起来开销更低，所以 MVCC 只是在 **读操作** 远多于 **写操作** 的情况下

MVCC 只在 **REPEATETABLE READ** **READ COMMITTED** 两个隔离级别下工作

##### 版本控制的工作方式

在 InnoDB 当中，MVCC 会在每一行记录后面保存两个隐藏的列，一个保存了 **行的创建时间**，一个保存了 **行的过期时间**，这两个时间是系统版本号，每一次事务开始的时候会自动递增，然后把这个版本号当作事务的版本号，用来和查询得到的每行记录的版本号进行比较，这样每一次事务开始的时候都得到了这个时间点的数据快照，无论事务需要运行多长的时间都可以使得它的数据是一样的

MVCC 的具体工作方式要分四种 **SELECT** **INSERT** **DELETE** **UPDATE**

###### SELECT

**SELECT** 的操作通常会返回一个数据集，所以 MVCC 模式下的 SELECT 会以下面两个要求来塞选数据

- InnoDB 只查找比当前事务把版本早的系统版本，也就是说行的系统版本要小于或者等于当前事务版本，这样可以确保得到的每一行数据，要么是事务开始前就存在的，要么是事务自己插入或者修改的
- **行的过期时间** 标记要么没有定(为空) 要么大于当前的事务版本号(这样就表示事务读取到这一行的时候，这个数据是没有被删除的)

###### INSERT

每插入一行新的数据就在这行数据的 **行创建时间** 当中填入当前事务的版本号

###### DELETE

删除一行数据的时候就更新这行数据的 **行过期时间** 为当前事务的版本号

###### UPDATE

将插入一行新的数据，把这行新的数据的 **行创建时间** 填入当前事务版本号，将原被更新的数据的 **行过期时间** 更新为当前事务版本号

## 查询

#### 查询执行过程

1. 客户端发送查询到服务器
2. 服务器检查缓存是否命中，若命中则直接返回
3. 服务器解析 SQL，并对 SQL 进行预处理
4. 优化器根据处理好的 SQL 生成执行计划
5. Mysql 根据执行计划，调用存储引擎的 API 进行查询
6. 把查询结果返回客户端

*!* 进行大查询的时候，在调用存储引擎的 API 时，查询集合会占用大量的内存，直到查询执行完毕才会释放内存

#### 查询状态

每一个链接都有它自己的状态，该状态表示了 mysql 当前正在做什么

- Sleep 等待客户端发送新的请求
- Query 执行查询或者将结果返回给客户端
- Lokced 等待获取锁权限
- Analyzing and statistics 收集存储引擎的统计信息
- Copying to map table 正在执行查询，并且将结果集复制到一个临时表当中
- Sorting result 对结果集进行排序
- Sending data 在多个状态之间传输数据 || 生成结果集 || 向客户端返回数据

#### 查询缓存

查询进入到服务器的时候，如果服务器的查询缓存是被打开的，那么 MySQL 会先看这次查询是否先命中了缓存，命中检查是通过一个大小写敏感的哈希操作执行的，所以就算有一个字符匹配不上也不会命中，如果命中缓存，还需要在这里检查一下用户的权限. 如果都没有问题则返回数据

#### 语法解析器

语法解析器会使用 MySQL 的愈发规则验证和解析查询，最后根据 SQL 语句生成一颗解析树，例如验证关键字是否正确，关键字顺序是否正确

#### 预处理器

预处理器根据得到的解析树再更具 Mysql 的谷子额进一步检查解析树是否正确，例如: 检查数据表和数据列是否存在等

#### 查询优化器

一个合法的语法解析树有很多中执行的方式，查询解析器根据自身的模型选择一条最合适的执行方式去执行

优化策略的参考因素: **每个表或者索引的页面个数** **索引的基数** **索引和数据行的长度** **索引的分布情况**

##### 优化策略

静态优化和动态优化

- 静态优化 类似于“静态编译”，在整个查询当中执行一次，静态优化执行一次后就一直存在，例如在 `where` 条件当中通过一些简单的代数变换换成另外的一种等价方式

- ##### 动态优化 类似于“动态编译”，每次查询的时候都需要根据上下文的信息和别的因素来动态调节

##### 优化类型

- 重新定义关联表的顺序
- 外链接转化成一个内链接，只是将等价于内连接的外连接操作转化成内连接
- 等价变换规则简化表达式，例如 (5 = 5 AND a > 5) 优化成 a > 5
- 优化 `COUNT(*)` 一些索引当中会记录表的行数，所以这个函数相当于一个常数
- MIN() MAX() 优化 在基于 B-Tree 数据结构的索引上，MIN() 相当于 B-Tree 最左边的数，MAX() 相当于最右边的数
- 覆盖索引扫描 如果索引当中有数据行，那么就可以直接获取到数据
- 子查询优化 MYSQL 可以在特定情况下，将子查询转化成一种效率更高的形式

#### 关联查询如何执行

MySQL 对任何关联都执行潜逃循环关联操作，现在一个表当中取出单条记录，然后再嵌套循环到下一个表当中寻找匹配的行，一次下去，直到所有的表当中匹配的行为止，再最后一个表当中，找到所有匹配行，如果最后一个表也没有了，再返回再找是否有更多的匹配记录。

如果要执行四个表 **tb1** **tb2** **tb3** **tb4** 的关联操作，Mysql 会从一个表开始一直嵌套循环、回溯完成所有的操作，所以可能就会是

```
              join
           ---------
           |       |
          join    tb4
       ---------
       |       |
      join    tb3
    --------
    |      |
   tb1    tb2
```

#### 关联查询优化器

在各种表的关联顺序当中找到一个代价最小的关联顺序，然后生成以课最优的执行树

关联优化器会便利每一张表逐个做嵌套循环计算每一颗可能的执行计划树的成本，当表数量很多(超过 optimizer_search_depth 参数)的时候就会使用贪婪算法来计算

#### 排序优化

除 B-Tree 索引外，一些索引没有办法排序就需要 mysql 自己排序，mysql 使用两个排序算法

- 两次传输排序 读取出行指针和排序的列中的字段，排好序后再去数据表当中找到数据，占用的空间少，但是由于两次读取表数据，会慢一点
- 单次传输排序 读取出需要排序的列和查询需要的列，排好序后直接返回，占用的空间多，由于只读表一次所以效率会快一点

#### 返回结果给客户端

MYSQL 将结果集返回给客户端是一个增量、逐步的过程，当服务器开始生成第一条记录的时候m Mysql 就可以开始向客户端逐步返回结果集了

## 数据库调优

#### 慢查询

在 Mysql 执行任务时，我们把查询的时间超过指定时间的查询叫做慢查询

- 开启慢查询功能 `show variable like slow%;`
- 查看慢查询的时间定义 `show variable like 'long%';`
- 设置慢查询的时间 `set long_query_time = 0.0001;`
- 保存慢查询到日志 `set global slow_query_log = ON;`

#### 分解关联查询

将联表查询分解成为多个单表查询，有如下的优势

1. 减少了一次需要锁定的表的数量，从而减少了锁竞争
2. 应用层做组合，可以达到某些记录只查询一次，这样减少了冗余
3. 提高缓存的应用效率

#### 切分查询

由于 Mysql 的链接与断开链接都很轻量级，所以如果在通讯允许的情况下，是可以将一个大查询切成多个小查询，但也需要考虑实际情况

把一个大数量级的查询切分成为多个小数量级的查询

例如: 服务器定时清理数据，假设每次清理需要清理100万条数据，那么一次性的运行这个查询，就需要锁住很多数据、占满整个事务日志、耗尽系统的资源等等，但是如果切换成多个小数量级的查询，就会使得服务器能够有足够的精力去响应别的查询

#### 是否查询了不必要的数据

1. 由于查询的语句没有做限制例如 `limit` 会取出多余的没有必要的数据行
2. 由于错误的使用了 `select *` 导致取出了多余的没有必要的数据列

#### 是否扫描了全表

可以建立合适的索引来避免

#### 经验

1. 首先考虑在 `where` `order by` 的列上建立索引
2. 尽量避免使用 `or` 否则索引会失效，例如 `select number from t where id = 10 or id = 20` 因改为 `select number from t where id = 10 UNION all select number from t where id = 20`
3. 不要在 `where` 子语句当中使用表达式与函数操作，这样无法使用索引，例如 `select number from t where id/2 = 100` 因改为 `select number from t where id = 50`
4. 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引
5. 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致
6. 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段 **sex** **male** **female** 几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用
7. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引
8. 应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源
9. 尽可能的使用 varchar/nvarchar 代替 char/nchar，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些
10. 任何地方都不要使用 select * from t，用具体的字段列表代替 `*`，不要返回用不到的任何字段
11. 尽量避免大事务操作，提高系统并发能力

## 分库分表

#### 什么是分表

如果有两张 user_0 user_1 表，按照它的自增长 id 数列来分表，`id % 2 == 0`，则在 user_0 表当中，如果 `id % 2 == 1` 则在 user_1 表当中

查询时，user_#{number}，其中 number 要为可变参数，而且不能有 “”，参加 $ 与 # 的区别

#### 分表的种类

##### 水平拆分

也就是把表横向切一刀，数据表的结构还是不变，但是数据量变了，这多出来的这些数据量塞到另外的表上去

##### 垂直拆分

也就是把表纵向划一刀，数据表的结构变得更细来了，把原来与该表无关的数据信息或者结构都切换到新的表上去，这样全表扫描的时候，所需要的时间更少

#### 如何分表

##### 使用工具

例如 mycat

第一步在 conf 文件当中配置分库信息

然后修改负载的方式，在客户端直接链接 mycat 就能转发请求

url:http://blog.csdn.net/leisure_life/article/details/78616106

##### 自定义策略

例如提前把一张表分作好几张，然后再根据特定的策略把查询、更新语句打到特定的表上去执行

这样的方法有 hash、id值区间划分等等方法

#### 为什么要分表

在应用程序运行的时候，会有一些数据表会被频繁的插入与修改，就会使得数据表的大小增长很快，这个时候如果当数据的量到一定的程度的时候，会有存储空间的限制而且查询和更新的操作就会变得很慢，这个时候就会考虑把一张数据库表分成多张数据库表或者是多个数据库来存放原本的数据

1. 解决磁盘系统的最大限度

FAT16(最大分区2GB，最大文件2GB ，最大容16G)
FAT32(最大分区32GB，最大容量2TB，最大文件32G)
NTFS(最大分区2TB，最大容量，最大文件2TB)
ext3(最大文件大小: 2TB，最大文件极限: 仅受文件系统大小限制，最大分区/文件系统大小: 4TB，最大文件名长度: 255 字符)

2. 减少锁的竞争

如果把数据分到不同的表当中去，当一个事务正在更新的时候，如果获取的是一个表锁，那么插入操作很有可能不是与更新操作位于同一张表上面，就可以减少锁的竞争的产生

3. 减少 sql 查询的时间

分库分表可减少一张表的数据量，这样就可以减少一条 sql 运行的时间，就可以使得别的 sql 等待时间减少

## 基本概念

#### 内联接

内联接使用比较运算符根据每个表共有的列的值匹配两个表中的行。例如，检索 students和courses表中学生标识号相同的所有行

#### 外联接

外联接可以是左向外联接、右向外联接或完整外部联接。   

1）LEFT JOIN 或 LEFT OUTER JOIN     

左向外联接的结果集包括 LEFT OUTER 子句中指定的左表的所有行，而不仅仅是联接列所匹配的行。如果左表的某行在右表中没有匹配行，则在相关联的结果集行中右表的所有选择列表列均为空值。       

2）RIGHT JOIN 或 RIGHT  OUTER  JOIN     

右向外联接是左向外联接的反向联接。将返回右表的所有行。如果右表的某行在左表中没有匹配行，则将为左表返回空值。       

3）FULL JOIN 或 FULL OUTER JOIN

完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。

#### 子查询

子查询就是查询中又嵌套的查询，嵌套的级数随各数据库厂商的设定而有所不同，一般最大嵌套数不超过15级，实际应用中，一般不要超过2级，否则代码难以理解.

最普遍的作用是当作上层查询的限制条件，比如select a from b where a in (select a from c where x=y) ，现实世界各种系统中，各式各样的关系，这样子查询从别处提取数据作为另一个查询的条件，这样子查询的作用就显示出来了

#### 关联查询

关联查询使用两个表的相关联的键为依据，合并两个表进行查询

比较常见的比如某工厂　生产X表　里面有 a　日期 b　订单　两字段 ，　销售Y表　b 订单　d　购买客户　，现在我们想看到某天是哪些客户买的东西　然后连接 x y表得到 a b d 这样　整个数据明细就出来了　

# Spring

## Bean 的生命周期

一般来讲，Bean 是 Java 实例，当 new 创建的对象，当他没有任何引用的时候，就会被垃圾回收机制回收，而 Bean 在 Spring 框架当中回不回收由 Spring 说了算

Bean 的生命周期有：实例化阶段、依赖注入阶段、初始化阶段、使用阶段、销毁阶段。

1. 实例化阶段，在我理解，就是为对象分配空间，也就是 new 过程。
2. 依赖注入过程，主要是在配置文档当中，需要对某些属性注入实例，这个时候会去从 IOC 当中获取实例，如果 IOC 当中没有这个 bean，便会触发这个 bean 的创建过程。
3. 当注入完成后，需要完成初始化的工作，如果这个类实现了 InitializingBean 接口的 afterPropertiesSet 方法，或者在 xml 当中配置了 initMothed，就回去调用这两个方法，这个阶段可以让一些配置工作在这完成，让 Bean 成为一个可用的实例。
4. Bean 的使用阶段，就是各种调用。
5. 在销毁过程当中，如果这个类实现了 DisposableBean 接口的 destroy 方法，或者在 xml 当中配置了 destroy-method 方法，就会在容器准备移除这些 Bean 的时候，调用这两个方法，这个方法一般用来释放资源。

## Bean 初始化过程

第一步，继承配置文件信息

通过 super 关键字，调用父类 AbstractApplicationContext 的初始化方法。在这个初始化方法当中，会执行两个过程，第一个过程，创建一个新的 AbstractApplicationContext，第二个过程，如果在构造方法当中传入了一个 ApplicationContext ，那么会把这个 ApplicationContext 当中的 Environment 合并到新的 AbstractApplicationContext 的 Enviroment 当中，Environment 当中存放了当前 ApplicationContext 的配置文件信息。

第二步，定位 BeanDefinition

传入的字符串会被 AbstractEnvironment 当中持有的 AbstractPropertyResolver 当中的 PropertyPlaceHolderHelper 逐一解析，并在 AbstractRefreshableConfigApplicationContext 当中被持有。

这个Resource定位指的是BeanDifinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDifinition的使用都提供了统一的接口。

对于这些BeanDifinition的存在形式，相信大家都不会感到陌生。比如，

在文件系统中的Bean定义信息可以使用FileSystemResource来进行抽象。

在类路劲中的Bean定义信息可以使用ClassPathResource。

这个定位过程类似于容器寻找数据的过程，就想水桶装水先要把水找到一样。

第三步，载入与解析 BeanDefinition

这个载入过程是把用户定义好的Bean表示成Ioc容器内部的数据结构，而这个容器内部的数据结构就是BeanDifinition。
具体来说，BeanDifinition实际上就是POJO对象在IOC容器中的抽象，通过这个BeanDifinition定义的数据结构，使IOC容器能够方便的对POJO对象也就是Bean进行管理。

整个过程通常发生在 refreshBeanFactory 方法当中，这个方法规定了 AbstractApplicationContext 的子类必须要实现配置文件的载入过程，在这个过程当中，
通常会销毁以前的 BeanFactory 和 BeanFactory 当中的 Bean，然后创建一个新的 BeanFactory，并执行 loadBeanDefinitions 方法，在这个方法当中，通常会解析以 Resource 或者 String 类型表达的配置文件的所在位置。整个过程当中会通过把要解析的 Resource 放入到一个统一的 HashSet 当中，然后进行 IO 生成一个 Document 对象。接下来就是注册 Document 对象当中的 BeanDefinition 。

第四步，注册

这个操作是通过调用BeanDifinitionRegistry借口来实现的。这个注册过程把载入过程中解析得到的BeanDifinition向Ioc容器进行注册。
在阅读源码中可知，在IOC容器内部将BeanDifinition注入到一个HashMap中去，Ioc容器就是通过这个HashMap来持有这些BeanDifinition数据的。

初始化 ReaderContext 的时候，会把 DefaultLisableBeanFactory 当中坐 BeanDefinitionRegistry 注入进去，在后面调用 BeanDefinitionRegistry 的 registerBeanDefinition 方法的时候，就把 BeanDefinition 全部注入到 beanDefinitionMap 当中了。

## IOC

### 什么是  IOC

即控制反转，是一种设计思想，在Java开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。

### 依赖注入的过程

依赖注入的过程是用户第一次向 IOC 容器索要 Bean 的时候发生的，有特殊情况，也就是在 BeanDefinition 信息当中通过控制 lazy-init 属性来让容器完成对 bean 的预示例化

依赖注入主要有两个过程，一是 bean 示例化，二是依赖解析与注入

在createBeanInstance方法中，根据指定的初始化策略，使用静态工厂、工厂方法或者容器的自动装配特性生成 java 实例对象

然后接下来首先对属性进行解析，如果属性类型不转换，那么直接准备依赖注入，然后通过调用 BeanWrapper 当中的方法来完成依赖注入

在创建和对象依赖注入的时候，都是依据 BeanDefinition 的信息来递归调用完成的，第一个在上下文体系当中查找是否有需要的 Bean 和创建 Bean的递归调用，第二个是通过递归调用容器的 getBean 方法获得当前 bean 依赖的 bean，同时也触发对依赖 Bean 的创建和注入过程

## AOP

### 什么是 AOP

AOP 是一种模块化机制，把业务程序当中一些可以被大部分业务复用或者与业务无关的处理流程抽取出来，形成一个单独的方法，
这样使得在业务代码当中不包含特定领域问题的调用。
然后把这样的业务逻辑和特定领域问题通过切面来封装和维护。这样就可以把原本分散在整个应用程序当中的变动就可以更好的被管理起来

### 动态代理

动态代理类的源码是在程序运行期间由JVM根据反射等机制动态的生成，所以不存在代理类的字节码文件。代理类和委托类的关系是在程序运行时确定。

### 静态代理

所谓静态也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。

### Spring AOP 的实现

生成 AOP 代理类，是从 ProxyFactoryBean getObject 方法中开始的

第一步，getObject 当中首先调用 initializeAdvisorChain 方法，对通知器进行初始化，为代理对象的生成做好准备

在 initializeAdvisorChain 方法当中，只会初始化一次，初始化过后不会再初始化。

完成通知器链后，从 IOC 容器当中获取到通知器，然后把取得通知器加入到拦截链当中，这个过程在 addAdvisorOnChainCreation 方法中实现

第二步，需要对 singletion 与 prototype 的 bean 做分别的初始化工作

在这个过程当中，ProxyFactoryBean 会去读配置，例如代理的方法调用的接口等等，为生成代理对象做准备，然后把创建具体代理对象的过程交给 AopProxy 来完成

AopProxy 有两个子类，一个是 JdkDynamicProxy 一个是 Cglib2AopProxy，这个两个子类分别用 JDK 和 CGLIB 来生成代理对象

具体的代理过程是 ProxyFactoryBean 的基类 AdvisedSupport 当中获取 AopProxyFactory 根据 AdvisedSupport 当中封装的信息来创建 AopProxy 来实现的，所以在整个过程当中 ProxyFactoryBean 充当 AopProxy 与 IOC 容器之间的桥梁，为 AopProxy 提供数据支持

在生成 AOP 代理对象的过程当中，如果代理是接口类的实现就使用 jdk 方式生成，否则使用 CGLIB。因为 jdk 只能代理接口类的实现，所以需要引入 CGLIB 代理方式，但是 CGLIB 需要引入 ASM 包，便选择两种代理方式结合

对 jdk 与 CGLIB 具体技术的使用，和实现层次的代理对象的生成，都是 spring 封装在 JdkDynamicAopProxy 与 CglibProxyFactory 当中的

## 事务

### 什么是 Spring 事务

事务Transaction，它是一些列严密操作动作，要么都操作完成，要么都回滚撤销。Spring事务管理基于底层数据库本身的事务处理机制。

### 如何实现

（1）编程式事务管理对基于 POJO 的应用来说是唯一选择。我们需要在代码中调用beginTransaction()、commit()、rollback()等事务管理相关的方法，这就是编程式事务管理。

（2）基于 TransactionProxyFactoryBean的声明式事务管理

（3）基于 @Transactional 的声明式事务管理

（4）基于Aspectj AOP配置事务

### 事务传播性

事务传播行为就是多个事务方法调用时，如何定义方法间事务的传播。Spring定义了7中传播行为：

（1）propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是Spring默认的选择。

（2）propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。

（3）propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。

（4）propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。

（5）propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

（6）propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。

（7）propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作。

# MyBatis

## MyBatis 工作流程

1. 加载配置文件，会加载全局配置文件、Sql映射文件
2. 创建 SessionFactory ，然后用 SessionFactory 来读取配置文件当中的内容
3. 创建 Session，Session 会在 SessionFactory 当中被创建，Session 是一个接口，包含了对数据的基本操作
4. 创建 Executor，Executor 帮助 Session 来执行 Sql 代码
5. 封装 Sql 对象，Executor 把要处理的 Sql 信息装到 MappedStatemen 对象当中，这里面有 Sql 、参数、结果信息
6. 把 Sql 对向提交并且执行

## Statement 与 PrepareStatement 区别

动态参数：PrepareStatement 支持动态参数的传入，但是 Statement 不支持动态参数的传入

编码：PrepareStatement 可以避免如单引号的编码麻烦，Statement 不可以

预编译：PrepareStatement 支持预编译，而 Statement 不支持

出错是否便于查找：PrepareStatement 的高级特性决定如果 Sql 不容易查出来，但是 Statement 容易查

安全：PrepareStatement 可以防止 Sql 注入，而 Statement 不可以

## 什么是 SQL 注入

Sql 注入指的是通过无参数的拼接来查找数据库当中的数据

例如查找的 sql 语句为

```java
String sql = "select * from user where name = " + username;
```

username 是从前段页面传入的，如果 `username ="or 1=1";`，那么就会获取数据库的大部分数据

# 操作系统



# 计算机网络

## 四层结构

　　┌─────┐
　　│应用层│
　　├─────┤
　　│传输层│
　　├─────┤
　　│网络层│
　　├─────┤
　　│链路层│
　　├─────┤


1. 链路层

负责在网络链路上传递信息
0

2. 网络层

IP 协议，提供源于端点之间的联系

3. 传输层

TCP 协议，提供可靠连接

4. 应用层

HTTP 协议，向应用程序提供访问网络资源的API

## 七层结构

　　┌─────┐
　　│　应用层　│←第七层
　　├─────┤
　　│　表示层　│
　　├─────┤
　　│　会话层　│
　　├─────┤
　　│　传输层　│
　　├─────┤
　　│　网络层　│
　　├─────┤
　　│数据链路层│
　　├─────┤
　　│　物理层　│←第一层
　　└─────┘

1. 物理层

负责最后将信息编码成电流脉冲或其它信号用于网上传输

2. 数据链路层

通过物理 网络链路提供可靠的数据传输。

3. 网络层

负责在源和终点之间建立连接。它一般包括网络寻径，还可能包括流量控制、错误检查等。

4. 传输层

向高层提供可靠的端到端的网络数据流服务。传输层的功能一般包括流控、多路传输、虚电路管理及差错校验和恢复。

5. 会话层

建立、管理和终止表示层与实体之间的通信会话。通信会话包括发生在不同网络应用层之间的服务请求和服务应答，
这些请求与应答通过会话层的协议实现。它还包括创建检查点，使通信发生中断的时候可以返回到以前的一个状态。

6. 表示层

提供多种功能用于应用层数据编码和转化，以确保以一个系统应用层发送的信息可以被另一个系统应用层识别。
表示层的编码和转化模式包括公用数据表示格式、性能转化表示格式、公用数据压缩模式和公用数据加密模式。

7. 应用层

向应用程序提供访问网络资源的API（Application Program Interface，应用程序接口）组成

## URI

叫做统一资源标识符，唯一的标示一个资源，就像身份证 id 一样

强调标识某一个资源

比如，http://www.sina.com.cn代表了新浪网，admin@qq.com代表了某一个人的qq邮箱，你的qq号也是一个URI(腾讯服务器内可以识别就是你的QQ账户)

## URL

叫统一资源定位符，标识一个互联网资源的位置，并指定对其进行操作或获取该资源的方法。可能通过网络“位置”进行标识。

强调标识某一个地点

URI 是 URL 的父集

## URI 与 URL

URI强调的是给资源标记命名，URL强调的是给资源定位

URI标记了一个网络资源，仅此而已；  URL标记了一个WWW互联网资源（用地址标记），并给出了他的访问地址。

## TPC

### TCP 三次握手

1. 客户端通过向服务器端发送一个SYN消息来创建一个主动打开请求，客户端把这段连接的消息的序号设定为随机数A。
2. 服务器端应当为一个合法的SYN回送一个SYN/ACK。ACK的确认码应为A+1，SYN/ACK包本身又有一个随机产生的序号B。
3. 最后，客户端再发送一个ACK。当服务端收到这个ACK的时候，就完成了三路握手，并进入了连接创建状态。此时包的序号被设定为收到的确认号A+1，
   而响应号则为B+1。

### TCP 三次握手的中间状态

如果服务器端接到了客户端发的 SYN 并且回复 SYN-ACK 后，客户端掉线了，服务器端没有收到客户端回来的ACK（也就是第三部客户端的应答时候），那么，这个连接处于一个中间状态，即没成功，也没失败。
于是，服务器端如果在一定时间内没有收到的 TCP 会重发 SYN-ACK。如果重发达到一定次数，那么 TCP 才会断开这个连接。

### TCP 为什么要握手三次

1. 如果两次，那么服务端无法确定服务端的信息客户端是否能收到，所以如果服务端先说话，可能后面的客户端都收不到，会出现问题
2. 如果四次，那么就造成了浪费，因为在三次结束之后，就已经可以保证客户端可以给服务端发信息，客户端也可以收到服务端的信息

### TCP 四次挥手

1. TCP 客户端发送一个 FIN，用来关闭客户到服务器的数据传送。
2. 服务器收到这个 FIN，它发回一个 ACK，确认序号为收到的序号加 1。
3. 服务器关闭客户端的连接，发送一个 FIN 给客户端。
4. 客户端发回 ACK 报文确认，并将确认序号设置为收到序号加 1。

### TCP 为什么要挥手四次

因为客户端与服务端分别释放资源都需要两次才能确认已经释放完毕

### TCP 与 UDP 区别

1. TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2. TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付
3. 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

### 滑动窗口协议

1. TCP协议的两端分别为发送者A和接收者B，由于是全双工协议，因此A和B应该分别维护着一个独立的发送缓冲区和接收缓冲区

2. 发送窗口是发送缓存中的一部分，是可以被TCP协议发送的那部分，其实应用层需要发送的所有数据都被放进了发送者的发送缓冲区

3. 每次成功发送数据之后，发送窗口就会在发送缓冲区中按顺序移动，将新的数据包含到窗口中准备发送

4. 发送窗口中相关的有四个概念：已发送并收到确认的数据（不再发送窗口和发送缓冲区之内）、已发送但未收到确认的数据（位于发送窗口之中）、
   允许发送但尚未发送的数据以及发送窗口外发送缓冲区内暂时不允许发送的数据

- 窗口

  对应的是一段可以被发送者发送的字节序列，其连续的范围称之为“窗口”

- 滑动

  是指这段“允许发送的范围”是可以随着发送的过程而变化的，方式就是按顺序“滑动”

### 滑动窗口协议过程

假设 A 给 B 发送数据

在 TCP 建立的时候，B 会告诉 A 自己的接受的窗口的大小，比如为 20

然后 A 开始给 B 发送消息，发送完毕后，窗口还不能后移，要收到 B 的确认后，窗口才能往后滑动，离开已经发送了的数据

当 B 接收数据后，B 收到连续的分组数据后会确认发送，然后自己的窗口会往后滑动，但是对于乱序的数组则会先保留下来

### 拥塞控制

#### 慢启动过程

设置一个 Congestion Window 参数，表示发送的数据的大小

1. 连接建好的开始先初始化cwnd(Congestion window) = 1，表明可以传一个MSS(Maximum Segment Size，最大报文长度)大小的数据。

2. 每当收到一个ACK，cwnd++; 呈线性上升

3. 每当过了一个RTT(往返时间)，cwnd = cwnd*2; 呈指数让升

4. 当 cwnd 达到了上限的时候也就是 cwnd >= ssthresh，一般来讲 ssthresh 的大小为 65535 字节，就会进入拥塞避免算法

#### 拥塞避免

过程

1. 收到一个ACK时，cwnd = cwnd + 1/cwnd

2. 当每过一个RTT时，cwnd = cwnd + 1

#### 快速恢复

快速恢复发生在网络发生拥堵之后，如果发送方连续收到三个确认，那么不是进入慢启动状态，而是进入到快速恢复的状态

1. 当发送发连续接收到三个确认时，就执行乘法减小算法，把慢启动上限（ssthresh）减半，但是接下来并不执行慢开始算法。

2. 此时不执行慢启动算法，而是把cwnd设置为ssthresh的一半，然后执行拥塞避免算法，使拥塞窗口缓慢增大。

## HTTP

### 什么是 HTTP

HTTP 是一种文档传输协议，主要运用在 WEB 应用当中。在网络的 TCP/IP 协议族 4 个层次当中，位于应用层。它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。简捷、快速的方式，适用于分布式超媒体信息系统。

### HTTP 工作流程

当客户端访问一个域名的时候，会先用 DNS 协议解析域名得到对应的 IP 地址，然后通过 HTTP 协议生成针对目标 WEB 服务器的 HTTP 请求报文

然后将 HTTP 报文传给传输层的 TCP 协议，按照 TCP 协议把报文分割成多端，然后保证每一段都可靠的传给对方

接着位于网络层的 IP 协议曾，在路由器当中利用 IP 地址与 Mac 地址寻找合适的中转站地址，传送报文

当服务端收到报文后，通过 TCP 协议把报文组合起来，上传给 HTTP 协议

应用层的 HTTP 协议解析报文得到内容并且响应

### HTTP 特点

1. 支持客户/服务器模式，基于TCP实现
2. 简单快速
   客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、POST、DELETE、PUT。每种方法规定了客户与服务器联系的类型不同。
   由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快
3. 灵活
   HTTP允许传输任意类型的数据对象。正在 传输的类型由 Content-Type 加以标记
4. 短连接
   短连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间
5. 无状态
   HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，
   这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快

### HTTP 缺点

1. 通讯使用明文，未加密，并且 TCP/IP 协议是可能会被窃听的网络，所以通讯内容可能会被窃听
2. 没有验证通讯方的身份，因此可能会遭遇伪装
3. 没有办法验证报文的完整性，所以可能会被篡改

### HTTP 方法

get 表示获取资源

post 表示传输实体主体

put 表示传输文件

head 获取报文首部，与 GET 一样只是不返回报文主体内容

delete 删除文件

options 查看该资源支持何种何种请求方法，例如支持 GET 或者 HEAD方法

trace 追踪路径，让 web 服务器将之前的请求通讯环回复给客户端

#### GET 与 POST 区别

1. 资源角度：get 是从服务器端获取资源，post 是向服务区发送数据
2. 提交方式：get 向服务器提交 URL 的方式来通通信，post 通过 Html header 当中提交
3. 获取数据方式：get：服务端用 Request.QueryString 来获取变量的值；post：用 Request.Form 来提交数据的值
4. 数据大小：get 最多 1024 字节；post 没有大小限制
5. 安全：get 的信息会在地址栏显示；post 信息不会

### HTTP 1.0 与 1.1 区别

1. HTTP 1.1支持长连接（PersistentConnection） keep-alive

  HTTP 1.0 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。

  HTTP 1.1 则支持持久连接，Connection 请求头的值为 Keep-Alive 时，客户端通知服务器返回本次请求结果后保持连接；Connection 请求头的值为 close 时，客户端通知服务器返回本次请求结果后关闭连接

2. HTTP 1.1 增加 host 字段

  在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

### HTTP 请求报文结构

Http 报文分两种：1.请求报文。2.响应报文，但大致结构都一样：

1. 报文首部

报文首部当中存放这 客户端 或者 服务端 请求或者响应的内容以及属性

2. 空行符

用来区分报文首部和报文主体

3. 消息体

存放了客户端给服务端的消息数据或者服务端给客户端的消息数据

#### 请求报文报文首部

请求报文当中的报文首部含有如下内容

1. 请求行

包含请求的方法、请求的 URI 和 HTTP 的版本

2. 首部字段

包含表示请求和响应的各种条件和属性的各类首部

#### 响应报文报文首部

响应报文的报文首部有如下内容

1. 状态行

状态行包含表明响应结果的状态码、原因短句、和 Http 版本

原因短句是描述信息，例如 200 有 OK 500 有 Internal Server Error

2. 首部字段

包含表示请求和响应的各种条件和属性的各类首部

### DNS 服务

DNS 是一个位于应用层的协议，用来解析域名对应的 IP 地址。

### HTTP 持久连接

Http 每一次请求过后都会选择断开连接，所以持久连接是为了避免因为多次请求而造成的频繁的连接建立和断开

持久连接在 HTTP/1.1 当中被提出，只要任意一端没有明显的提出断开链接，就保持 TCP 连接

在 HTTP/1.1 当中，所有的连接默认都是持久连接

持久链接当中的 HTTP 请求头中添加一个字段 Connection-keep alive，来保持两者之间的联系

### HTTP 管线化

在持久化之前，发送请求后需要等待并收到响应后，才能发送下一个请求。管线化技术可以让请求不用等待响应也可以直接发送下一个请求

管线化技术可以同时发送多个请求，提升了持久化之后的请求速度

### HTTP Cookie

Http 是无状态的协议，也就是对之前发送过的请求或者响应的状态感知得到，但在网站当中，又需要去记录例如登陆等等一些状态信息。

通过在请求和响应报文写入 Cookie 信息来保持这样的联系

客户端第一次向服务器发送请求的时候，获取到服务器的响应报文，保存响应报文当中的 Cookie 信息，然后在下一次发送请求信息的时候，把 Cookie 信息附带发送出去，然后服务器端收到了请求报文后，解析到 Cookie 信息得到以前的状态

### 状态码

1** 信息，接受的请求正在处理

2** 成功，操作被成功接收并处理

3**	重定向，需要进行附加操作以完成请求

4** 客户端错误，请求包含语法错误或无法完成请求

5** 服务器错误，服务器在处理请求的过程中发生了错误

**200**

200 正常处理

204 成功处理，但是响应参数当中不包任何实体内容

206 请求了一部分内容，服务器成功处理了这种请求

**300**

301 永久重定向，表示请求的资源以及被分配了新的 URI，以后需要使用现在指向的URI

302 临时重定向

303 请求的资源有另外的一个 URL 应使用 GET 方法来定向获取请求的资源

**400**

400 报文当中存在语法错误

401 表示需要通过 http 认证

403 表示服务器不允许访问这个资源

404 没有找到

**500**

500 表示服务端执行错误

503 表示服务端超出负载或者正在停机维护

### Session 与 Cookie 的区别

**存储地方**

Session 存放在服务端，表示一个会话从开始到结束的阶段

Cookies 存放在服务器，是服务器存储数据的一个回执单，可以用来保存部分不隐私的数据

**安全**

Session 位于服务端，不会被盗取

Cookies 的文件通过一定手段盗取并通过浏览器的承认后，就可以伪装成别人的请求来发送，所以不安全

## HTTPS 

### 什么是HTTPS

https 协议是 http 协议的加强版，它解决了 http 协议当中明文、传送方未知以及容易被篡改的问题。所以 http 协议加上加密处理和认证以及完整性保护等于 https

https 协议的通讯过程和 http 大致相同，但是优先和 ssl 协议通讯，再由 ssl 协议与 tcp 通讯，

ssl 可以在两端建立一个安全的通讯线路，并且加密内容，同时 ssl 可以通过验证证书的方式来验证合法性，

### 证书验证方式

1. 服务器 用RSA生成公钥和私钥
2. 把公钥放在证书里发送给客户端，私钥自己保存
3. 客户端首先向一个权威的服务器检查证书的合法性，如果证书合法，客户端产生一段随机数，这个随机数就作为通信的密钥，我们称之为对称密钥，
   用公钥加密这段随机数，然后发送到服务器
4. 服务器用密钥解密获取对称密钥，然后，双方就已对称密钥进行加密解密通信了

## IP 协议

### 什么是 IP 协议

IP 工作要从 IP 协议说起

IP 协议的主要内容是把各种数据包发送到目的，在 IP 协议当中，这个传输的过程依靠 IP 地址与 MAC 地址，IP 地址可以表示物理机处于何种网络结构当中，MAC 地址可以唯一的表示一台主机

在不同的局域网上进行传输的时候，利用 ARP 协议翻译 IP 地址，查找下一站中转设备的 MAC 地址，来搜索下一个中转的目标

### ARP 协议

ARP（Address Resolution Protocol）叫做地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，
以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。

## WebSocket

### 什么是 WebSocket

WebSocket 是一个网络协议，允许两个相连的端在一个单一的 TCP 连接上进行双向消息通讯。

在 WebSocket 当中，连接通过 HTTP 和 WebSocket 端点交互的方式建立。连接的发起者发送一个专门指定的 Http 请求，其中包含有 WebSocket 端点的 URL。这过程叫做打开阶段握手。如果服务器愿意接受连接，那么服务器就会生辰一个打开阶段握手响应的 HTTP 响应并返回给客户端。此时 TCP 连接就已经建立，能够保证 WebSocket 消息的往返传递。

WebSokcet 的连接一直保持活跃直到任意一方决定终止连接或者被某些因素导致连接中断

WebSocket 协议当中主要包含两个帧：控制帧与数据帧。控制帧用于控制内部功能逻辑的数据传输，例如关闭等；数据帧定义了携带应用数据的 WebSocket 传输的种类，文本型或者二进制型

### 如何创建一个 WebSocket

```java
// 声明一个端点，链接地址为 :ws://localhost:8080/hello
@ServerEndpoint("/hello")
public class HelloWorldEndpoint {


    //接受消息的时候被调用的方法
    @OnMessage
    public String hello(String message) {
        System.out.println("Received : "+ message);
        return message;
    }

    //端点第一次链接的时候被调用的方法
    @OnOpen
    public void myOnOpen(Session session，Endpoint endpoint) {
        System.out.println("WebSocket opened: " + session.getId());
    }

    //端点关闭的时候被调用的方法
    @OnClose
    public void myOnClose(CloseReason reason) {
        System.out.println("Closing a WebSocket due to " + reason.getReasonPhrase());
    }

    //这里处理异常
    @onErrot
    public void errorHandler(Throwable a){
        System.out.println("这里处理异常")
    }

}
```

当一个客户端与 Websocket 服务器建立链接的时候，就会有一个端点实例被创建，如果 WebSocket 端点有多个用户链接，那么 WebSocket 的实现将示例化多次，链接的每个新客户都会示例化一次

### WebSocket 生命周期

websocket 的生命周期有四个阶段

第一，打开阶段

这个阶段，Websokcet 会收到第一个事件叫走打开通知，表示到 Websocket 会话另一端的连接已经建立完成

第二，会话阶段

当打开通知被两端都收到的时候，就可以相互之间发送消息

第三，Error

在 Websokcet 运行的时候，会产生一些错误，一般会是两种：一种是致命错误，这种错误将导致链接关闭，无法再传送消息。第二种是非致命错误，WebSocket 可以自己选择是否继续发送消息或者接受消息

第四，关闭阶段

关闭阶段，无论哪个端点都可以自己主动的执行关闭事件，然后发送一个通信信息，告知另一端这边准备关闭了，不需要得到别人的确认，也可以直接关闭

### WebSocket Session

从浏览器客户端发起一系列 Http 请求的同一用户都会与同一个 HttpSession 相关联

WebSocket 的握手连接也是一种 Http 交互，所以每个 WebSocket Session 对象都与 Http Sesion 对应想有关系，在每个运行于 web 应用的 WebSocket 上都存在一个与它关联的 HttpSession 对象

如果 Http Session 被中断，也例如超时，那么 Websocket 实现会关闭 Webscoket Session

Session 表示的是与单个连接向关联的状态。

Session 在创建 WebSocket 连接的时候被创建，在创建的时候会被分配一个唯一的标识，一个客户端对应一个 Session

Session 可以获取 RemoteEndpoint 来连接另外一个端点，也可以管理 Session 端点本身例如关闭连接等等功能

### 如何获取 WebSocket Session

因为 webSocket 的连接建立阶段是通过 Http 请求完成的，所以如果要 webSocket 持有 HttpSession，在 WebSocket 当中这个过程是通过自定义类并且继承 Configurator 类并重写方法

```java
    public void modifyHandshake(ServerEndpointConfig sec，HandshakeRequest request，HandshakeResponse response) {

          HttpSession httpSession = (HttpSession) request.getHttpSession();
　　　　　　
          sec.getUserProperties().put(HttpSession.class.getName()，httpSession);
    }

```

在 HandshakeRequest 当中封装了 HttpSession，可以获取到，ServerEndpointConfig 可以把 HttpSession 保存起来

修改注解，再通过 EndPointConfig 来获取

```java

@ServerEndpoint(value = "/example"，
                configurator = GetHttpSessionConfigurator.class)
public class GetHttpSessionSocket
{
    private Session wsSession;
    private HttpSession httpSession;

    @OnOpen
    public void open(Session session，EndpointConfig config) {
        this.wsSession = session;
        this.httpSession = (HttpSession) config.getUserProperties()
                                           .get(HttpSession.class.getName());
    }

    @OnMessage
    public void echo(String msg) throws IOException {
        wsSession.getBasicRemote().sendText(msg);
    }
}

```

最后配置一个 web 的 Http 监听器

```java
public class RequestListener implements ServletRequestListener {

    public void requestInitialized(ServletRequestEvent sre)  {
        //将所有request请求都携带上httpSession
        ((HttpServletRequest) sre.getServletRequest()).getSession();
    }

    public RequestListener() {
    }

    public void requestDestroyed(ServletRequestEvent arg0)  {
    }
}

```

### WebSocket 消息通讯

Websocket 消息通讯支持三种消息类型：文本信息、二进制信息、Ping/Pong消息

文本消息 的两种发送方式

```java
//把消息全部发送过去
public void sendText(String args) throws IOException

//以片段的方式发送消息
public void sendText(String args，boolean isLast) throws IOException

```

二进制消息 的两种发送方式

二进制消息适合发送图片、音频这样的特殊格式的数据

```java
//整段发送消息
public void sendBinary(ByteBuffer data) throws IOException

//以片段的方式发送消息
public void sendBinary(ByteBuffer partialByte，boolean isLast) throws IOException

```

Ping/Pong 的发送方式

Ping/Pong 是用来检测连接的健康性和测算连接的效率的，一般最大为 125 个字节

```java
public void sendPing(ByteBuffer applicationData) throws IOException，IllegalArgumentException

public void sendPong(ByteBuffer applicationData) throws IOException，IllegalArgumentException

```

*！*

1. WebSocket 可以传送 Java 对象，取决于把 Java 对象转化成什么样的消息
2. 每当有新的客户端连接进来的时候，都会创建一个新的 Websocket 的端点
3. 任意时候只能有一个线程访问某一个端点
4. Java WebSocket API 可以保证消息以片段的方式发送时

# 系统架构

## CAP 理论

 它是一个经典的分布式系统理论。CAP 理论告诉我们 : 一个分布式系统不可能同时满足一致性(C:Consistency)、可用性(A:Availability)及分区容忍性(P:Partition tolerance) 这三个基本要求，最多只能同时满足其中两项。

- 一致性(C): 在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

- 可用性(A): 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求，也指好的响应性能，完全的可用性指的是在任何故障模型下，服务都会在有限的时间处理响应   

- 分区容忍性(P): 在网络分区的情况下，被分隔的节点仍能正常对外服务，简单可理解为“可靠性”（两个系统外界看来就是整体，如果系统不能通信了，成为分区。 如果不能保证分区容错性，则节点不能正常服务，不能服务就谈不上什么事务了，所以分区容错性是肯定要保证的）

## CAP 选择

- CA	    放弃分区容忍性，加强一致性和可用性。

- AP	    放弃一致性（这里说的一致性是强一致性），追求分区容忍性和可用性。

- CP	    放弃可用性，追求一致性和分区容忍性。

## BASE 理论

BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。

在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，它是用来对CAP定理进行进一步扩充的。BASE理论指的是：

- Basically Available（基本可用） 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性----注意，这绝不等价于系统不可用。

- Soft state（软状态）软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

- Eventually consistent（最终一致性）最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。

## 分布式环境中的并发问题

1. 避免集群内部并发

  避免在集群内部并发，因为集群内部的并发就会导致大量资源浪费，比如要做各种锁，但是如果真的设计到并发的话，可以根据业务，把并发计算的数据缩小到最小的粒度，
  然后在一个应用程度当中并行执行。例如，如果客户的数据之间是相互隔离的，那么我们就可以把同一个用户程序放在一个程序上运算，不同的用户数据可以在不同的应用程序上计算

2. 时间戳

  分布式环境中并发是没法保证时序的，无论是通过远程接口的同步调用或异步消息，因此很容易造成某些对时序性有要求的业务在高并发时产生错误。
  比如系统A需要把某个值的变更同步到系统B，由于通知的时序问题会导致一个过期的值覆盖了有效值。对于这个问题，常用的办法就是采用时间戳的方式

3. 串行化

  有的时候可以通过串行化可能产生并发问题操作，牺牲性能和扩展性，来满足对数据一致性的要求。比如分布式消息系统就没法保证消息的有序性，
  但可以通过变分布式消息系统为一个消息系统就可以保证消息的有序性了。

4. 数据库

  分布式环境中的共享资源不能通过 Java 里同步方法或加锁来保证线程安全，但数据库是分布式各服务器的共享点，可以通过数据库的高可靠一致性机制来满足需求。

5. 行锁

  有的事务比较复杂，无法通过一条sql解决问题，并且有存在并发问题，这时就需要通过行锁来解决，一般行锁可以通过以下方式来实现：

  - 对于Oracle数据库，可以采用select ... for update方式。这种方式会有潜在的危险，就是如果没有commit就会造成这行数据被锁住，其他有涉及到这行数据的任务都会被挂起，应该谨慎使用

  - 在表里添加一个标示锁的字段，每次操作前，先通过update这个锁字段来完成类似竞争锁的操作，操作完成后在update锁字段复位，标示已归还锁。
    这种方式比较安全，不好的地方在于这些update锁字段的操作就是额外的性能消耗

## 分布式锁

### 基于数据库

要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。

当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。

比如有这样一个方法 `public void swap(int a，int b)`，在数据库当中会建立这样一个这样的表

```sql
create table method(
  `id` int(11) not null auto_increament comment '主键'，
  `methond_name` varchar(64) not null comment '方法名'，
  'des' varchar(255) not null comment `参数`，
  `update_time` timestamp not null default current_timstamp on update conccuren_timestamp comment `保存数据的时间，自动生成的`
  primary key(id)，
  unique key `uidx_method_name` (`method_name`) using btree
) engine=innodb default charset=utf8 comment `锁定中的方法`

```

当我们调用一个方法的时候，就执行下面的语句

```sql
insert into method(method_name，des) values (method_name，des);
```

当我们释放锁的时候，就会执行下面的语句

```sql
delete from methd where method_name='method_name';
```

- 局限性

1. 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。(搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上)
2. 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。(只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。)
3. 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。(搞一个while循环，直到insert成功再返回成功。)
4. 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。(在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。)



# 数据结构

## 数组

### 什么是数组

数组是一个固定长度的存储相同数据类型的数据结构，数组中的元素被存储在一段连续的内存空间中。

### 优点

- 顺序表的内存空间连续。
- 尾插、尾删效率较高，时间复杂度是O(1)。
- 支持随机访问，可以高效的按下标进行操作，时间复杂度是O(1)。

### 缺点

- 在顺序表中间插入或删除元素时都涉及到元素的移动，效率较低，时间复杂度为O(N)。
- 顺序表长度固定，有时需要扩容。

### 时间复杂度

- 在数组末端增加/删除、定位、更新元素，只允许占 O(1) 的时间复杂度（平摊（amortized）去分配内存以获取更多空间）
- 在数组任何地方插入/移除元素，只允许 O(n) 的时间复杂度

### 空间复杂度

- 因为在内存中分配的空间邻近，所以有助于提高性能
- 空间需求 = （大于或等于 n 的数组容积）* 元素的大小。即便空间需求为 2n，其空间复杂度仍然是 O(n)

## 链表

### 什么是链表

链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。

### 优点

1. 链表的内存空间不连续。
2. 如果知道要处理节点的前一个位置，则进行插入和删除的复杂度为O(1);
3. 如果不知道要处理节点的前一个位置，则进行插入和删除的复杂度为O(N)。
4. 头插、头删的效率高，[时间复杂度](https://so.csdn.net/so/search?q=时间复杂度&spm=1001.2101.3001.7020)是O(1)。
5. 没有空间限制，不会溢出，可以存储很多元素。

### 缺点

链表不支持随机访问，查找元素效率低，需要遍历节点，时间复杂度是O(n)。

### 队列

队列是一种只允许在一端进行插入操作，另一端进行删除操作的线性表

先进先出

把队列的头尾相接的顺序存储结构成为循环队列

### 时间复杂度

- 在糟糕的实现情况下，使用链表所实现的队列，其入列和出列的时间复杂度将会是 O(n)。因为，你需要找到下一个元素，以致循环整个队列
- enqueue：O(1)（平摊（amortized）、链表和数组 [探测（probing）]）
- dequeue：O(1)（链表和数组）
- empty：O(1)（链表和数组）

## 堆

堆（数据结构）：堆可以被看成是一棵树，如：堆排序。

## 栈

是一种数据项按序排列的数据结构，只能在一端(称为栈顶(top))对数据项进行插入和删除。

栈（数据结构）：一种先进后出的数据结构。

## 树

由 n 个节点组成一个具有层次关系的集合。

## 二叉树

就是二叉树是每个节点最多有两个子树的树结构，经常被用作于二叉查找和二叉堆。

### 二叉树的特性

第n层上面最多有 2^(n-1) 个节点

深度为 k 的二叉树至多有 2^k - 1个节点

### 求二叉树当中的节点个数

```java
int GetNodeNum(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL) // 递归出口  
        return 0;  
    return GetNodeNum(pRoot->m_pLeft) + GetNodeNum(pRoot->m_pRight) + 1;  
}  

```

递归解法：
（1）如果二叉树为空，节点个数为0
（2）如果二叉树不为空，二叉树节点个数 = 左子树节点个数 + 右子树节点个数 + 1

### 分层遍历二叉树

相当于广度优先搜索，使用队列实现。队列初始化，将根节点压入队列。当队列不为空，进行如下操作：弹出一个节点，访问，若左子节点或右子节点不为空，将其压入队列。

```java
void LevelTraverse(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL)  
        return;  
    queue<BinaryTreeNode *> q;  
    q.push(pRoot);  
    while(!q.empty())  
    {  
        BinaryTreeNode * pNode = q.front();  
        q.pop();  
        Visit(pNode); // 访问节点  
        if(pNode->m_pLeft != NULL)  
            q.push(pNode->m_pLeft);  
        if(pNode->m_pRight != NULL)  
            q.push(pNode->m_pRight);  
    }  
    return;  
}  

```

### 二叉树变为有序双向列表

要求不能创建新节点，只调整指针。
递归解法：
（1）如果二叉树查找树为空，不需要转换，对应双向链表的第一个节点是NULL，最后一个节点是NULL
（2）如果二叉查找树不为空：
如果左子树为空，对应双向有序链表的第一个节点是根节点，左边不需要其他操作；
如果左子树不为空，转换左子树，二叉查找树对应双向有序链表的第一个节点就是左子树转换后双向有序链表的第一个节点，同时将根节点和左子树转换后的双向有序链 表的最后一个节点连接；
如果右子树为空，对应双向有序链表的最后一个节点是根节点，右边不需要其他操作；
如果右子树不为空，对应双向有序链表的最后一个节点就是右子树转换后双向有序链表的最后一个节点，同时将根节点和右子树转换后的双向有序链表的第一个节点连 接。

```java
/******************************************************************************
参数：
pRoot: 二叉查找树根节点指针
pFirstNode: 转换后双向有序链表的第一个节点指针
pLastNode: 转换后双向有序链表的最后一个节点指针
******************************************************************************/  
void Convert(BinaryTreeNode * pRoot，  
             BinaryTreeNode * & pFirstNode，BinaryTreeNode * & pLastNode)  
{  
    BinaryTreeNode *pFirstLeft，*pLastLeft，* pFirstRight，*pLastRight;  
    if(pRoot == NULL)   
    {  
        pFirstNode = NULL;  
        pLastNode = NULL;  
        return;  
    }  

    if(pRoot->m_pLeft == NULL)  
    {  
        // 如果左子树为空，对应双向有序链表的第一个节点是根节点  
        pFirstNode = pRoot;  
    }  
    else  
    {  
        Convert(pRoot->m_pLeft，pFirstLeft，pLastLeft);  
        // 二叉查找树对应双向有序链表的第一个节点就是左子树转换后双向有序链表的第一个节点  
        pFirstNode = pFirstLeft;  
        // 将根节点和左子树转换后的双向有序链表的最后一个节点连接  
        pRoot->m_pLeft = pLastLeft;  
        pLastLeft->m_pRight = pRoot;  
    }  

    if(pRoot->m_pRight == NULL)  
    {  
        // 对应双向有序链表的最后一个节点是根节点  
        pLastNode = pRoot;  
    }  
    else  
    {  
        Convert(pRoot->m_pRight，pFirstRight，pLastRight);  
        // 对应双向有序链表的最后一个节点就是右子树转换后双向有序链表的最后一个节点  
        pLastNode = pLastRight;  
        // 将根节点和右子树转换后的双向有序链表的第一个节点连接  
        pRoot->m_pRight = pFirstRight;  
        pFirstRight->m_pLeft = pRoot;  
    }  

    return;  
}  

```

### 求二叉树的深度

```java
int GetDepth(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL) // 递归出口  
        return 0;  
    int depthLeft = GetDepth(pRoot->m_pLeft);  
    int depthRight = GetDepth(pRoot->m_pRight);  
    return depthLeft > depthRight ? (depthLeft + 1) : (depthRight + 1);   
}  

```

递归解法：
（1）如果二叉树为空，二叉树的深度为0
（2）如果二叉树不为空，二叉树的深度 = max(左子树深度，右子树深度) + 1

### 先序遍历

前序遍历递归解法：
（1）如果二叉树为空，空操作
（2）如果二叉树不为空，访问根节点，前序遍历左子树，前序遍历右子树

```java
void PreOrderTraverse(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL)  
        return;  
    Visit(pRoot); // 访问根节点  
    PreOrderTraverse(pRoot->m_pLeft); // 前序遍历左子树  
    PreOrderTraverse(pRoot->m_pRight); // 前序遍历右子树  
}  

```

Visit 表示访问方法，比如读取值

### 中序遍历

中序遍历递归解法
（1）如果二叉树为空，空操作。
（2）如果二叉树不为空，中序遍历左子树，访问根节点，中序遍历右子树

```java
void InOrderTraverse(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL)  
        return;  
    InOrderTraverse(pRoot->m_pLeft); // 中序遍历左子树  
    Visit(pRoot); // 访问根节点  
    InOrderTraverse(pRoot->m_pRight); // 中序遍历右子树  
}  

```

Visit 表示访问方法，比如读取值

### 后序遍历

后序遍历递归解法
（1）如果二叉树为空，空操作
（2）如果二叉树不为空，后序遍历左子树，后序遍历右子树，访问根节点

```java
void PostOrderTraverse(BinaryTreeNode * pRoot)  
{  
    if(pRoot == NULL)  
        return;  
    PostOrderTraverse(pRoot->m_pLeft); // 后序遍历左子树  
    PostOrderTraverse(pRoot->m_pRight); // 后序遍历右子树  
    Visit(pRoot); // 访问根节点  
}  

```

### 特殊二叉树

#### 斜树

所有的节点都只有左子树的二叉树叫做左斜树

所有的节点只有右子树的二叉树叫做右斜树

#### 满二叉树

所有的分之节点都有左子树和右子树，并且所有的叶子都在同一层上

#### 完全二叉树

完全二叉树，除最后一层可能不满以外，其他各层都达到该层节点的最大数，最后一层如果不满，该层所有节点都全部靠左排

#### 平衡二叉树

平衡树是一种改进了的二叉查找树，平衡指所有叶子的深度趋于平衡，也就是左右子树的深度绝对差不超过 1

#### B 树与 B+树

是一种自平衡树，能够保持数据有序。

区别：

1. B+树中只有叶子节点会带有指向记录的指针（ROWID），而B树则所有节点都带有，在内部节点出现的索引项不会再出现在叶子节点中。

2. B+树中所有叶子节点都是通过指针连接在一起，而B树不会。


B+树的优点：

1. 非叶子节点不会带上指向记录的指针，这样就增加了可用的空间，一个块中可以容纳更多的索引项，一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点。

2. 叶子节点之间通过指针来连接，范围扫描将十分简单，而对于B树来说，则需要在叶子节点和内部节点不停的往返移动。

B树的优点：

1. 对于在内部节点的数据，可直接得到，不必根据叶子节点来定位。

#### 哈夫曼树

带权路径长度最小的二叉树称为赫夫曼树或最优二叉树。

# 算法

## 时间复杂度

空间复杂度是对一个算法在运行过程中所需要的时间的一个量度，同样反映的是一个趋势，我们用 O(n) 来定义。

空间复杂度比较常用的有：O(1)、O(n)、O(n²)。

## 空间复杂度

空间复杂度是对一个算法在运行过程中临时占用存储空间大小的一个量度，同样反映的是一个趋势，我们用 S(n) 来定义。

空间复杂度比较常用的有：O(1)、O(n)、O(n²)。

## 查找

### 线性搜索

按一定的顺序检查数组中每一个元素，直到找到所要寻找的特定值为止。是最简单的一种搜索算法。

时间复杂度：

- 最好 log( 1 ）
- 最坏 log( n )

### 二分查找

搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。

#### 适用场景

在有序数组中查找某一特定元素的搜索算法。

#### 时间复杂度

折半搜索每次把搜索区域减少一半，时间复杂度为 O( log(n) ）。

#### 空间复杂度

O( 1 )。虽以递归形式定义，但是尾递归，可改写为循环

### 分块查找

基于线性查找和二分查找改进的一种算法。

### 广度优先搜索 BFS

1. 首先将根节点放入队列中。
   1. 从队列中取出第一个节点，并检验它是否为目标。
   2. 如果找到目标，则结束搜寻并回传结果。
2. 否则将它所有尚未检验过的直接子节点加入队列中。
3. 若队列为空，表示整张图都检查过了——亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。
4. 重复步骤2。

#### 时间复杂度

复杂度为 O( |节点的数目| + |图中边的数目| )

#### 空间复杂度

复杂度为 O( |节点的数目| + |图中边的数目| )

#### 适用场景

图形搜索算法

并不适合解非常大的问题

广度优先搜索算法具有完全性。这意指无论图形的种类如何，只要目标存在，则BFS一定会找到。然而，若目标不存在，且图为无限大，则BFS将不会结束。

若所有边的长度相等，广度优先搜索算法是最佳解——亦即它找到的第一个解，距离根节点的边数目一定最少；但对一般的图来说，BFS并不一定回传最佳解。
这是因为当图形为加权图（亦即各边长度不同）时，BFS仍然回传从根节点开始，经过边数目最少的解；而这个解距离根节点的距离不一定最短

### 深度优先搜索算法 DFS

深度优先遍历的主要思想就是：首先以一个未被访问过的顶点作为起始顶点，沿当前顶点的边走到未访问过的顶点；当没有未访问过的顶点时，则回到上一个顶点，
继续试探访问别的顶点，直到所有的顶点都被访问。

沿着某条路径遍历直到末端，然后回溯，再沿着另一条进行同样的遍历，直到所有的顶点都被访问过为止。

#### 时间复杂度

最优：O( 1 )
最坏：O( log(n) )
平均：O( log(n) )

#### 空间复杂度

迭代：O( 1 )
递归：O( logn )

#### 适用场景

一种用于遍历或搜索树或图的算法。

## 排序

### 冒泡排序

1. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。
2. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。
3. 针对所有的元素重复以上的步骤，除了最后一个。
4. 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。


```java
public class BubbleSort {
　　public static void main(String[] args) {
　　　　int[] arr={6，3，8，2，9，1};
　　　　System.out.println("排序前数组为：");
　　　　for(int num:arr){
　　　　　　System.out.print(num+" ");
　　　　}
　　　　for(int i=0;i<arr.length-1;i++){//外层循环控制排序趟数
　　　　　　for(int j=0;j<arr.length-1-i;j++){//内层循环控制每一趟排序多少次
　　　　　　　　if(arr[j]>arr[j+1]){
　　　　　　　　　　int temp=arr[j];
　　　　　　　　　　arr[j]=arr[j+1];
　　　　　　　　　　arr[j+1]=temp;
　　　　　　　　}
　　　　　　}
　　　　} 
　　　　System.out.println();
　　　　System.out.println("排序后的数组为：");
 　　　　for(int num:arr){
 　　　　　　System.out.print(num+" ");
 　　　　} 
　　}
 }
```

#### 时间复杂度

O( n2 )

#### 空间复杂度

O( n ) + O( 1 )

### 插入排序

1. 从第一个元素开始，该元素可以认为已经被排序
2. 取出下一个元素，在已经排序的元素序列中从后向前扫描
3. 如果在以及排序的元素当中当前元素大于新元素，将该元素移到后面的位置
4. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置
5. 将新元素插入到该位置后
6. 重复步骤2~5

```java
public void doInsertSort(){
        for(int index = 1; index<length; index++){//外层向右的index，即作为比较对象的数据的index
            int temp = array[index];//用作比较的数据
            int leftindex = index-1;
            while(leftindex>=0 && array[leftindex]>temp){//当比到最左边或者遇到比temp小的数据时，结束循环
                array[leftindex+1] = array[leftindex];
                leftindex--;
            }
            array[leftindex+1] = temp;//把temp放到空位上
        }
    }
```

#### 时间复杂度

平均 O( n^2 )

最优 O( n^2 ) 

最差 O( n )

#### 空间复杂度

总共 O( n ) 需要 O( 1 ) 辅助空间

### 选择排序

```java
public class SelectionSort {
    public static void main(String[] args) {
        int[] arr={1，3，2，45，65，33，12};
        System.out.println("交换之前：");
        for(int num:arr){
            System.out.print(num+" ");
        }        
        //选择排序的优化
        for(int i = 0; i < arr.length - 1; i++) {// 做第i趟排序
            int k = i;
            for(int j = k + 1; j < arr.length; j++){// 选最小的记录
                if(arr[j] < arr[k]){ 
                    k = j; //记下目前找到的最小值所在的位置
                }
            }
            //在内层循环结束，也就是找到本轮循环的最小的数以后，再进行交换
            if(i != k){  //交换a[i]和a[k]
                int temp = arr[i];
                arr[i] = arr[k];
                arr[k] = temp;
            }    
        }
        System.out.println();
        System.out.println("交换后：");
        for(int num:arr){
            System.out.print(num+" ");
        }
    }
}
```

#### 时间复杂度

```
O( n2 )
```

#### 空间复杂度

```java
O( n )+ O( 1 ) 辅助空间
```

### 快速排序


```java
private static void QuickSort(int[] num，int left，int right) {
		//如果left等于right，即数组只有一个元素，直接返回
		if(left>=right) {
			return;
		}
		//设置最左边的元素为基准值
		int key=num[left];
		//数组中比key小的放在左边，比key大的放在右边，key值下标为i
		int i=left;
		int j=right;
		while(i<j){
			//j向左移，直到遇到比key小的值
			while(num[j]>=key && i<j){
				j--;
			}
			//i向右移，直到遇到比key大的值
			while(num[i]<=key && i<j){
				i++;
			}
			//i和j指向的元素交换
			if(i<j){
				int temp=num[i];
				num[i]=num[j];
				num[j]=temp;
			}
		}
		num[left]=num[i];
		num[i]=key;
		count++;
		QuickSort(num，left，i-1);
		QuickSort(num，i+1，right);
	}
```

#### 时间复杂度

O（nlogn）

### 希尔排序

希尔排序是基于插入排序的以下两点性质而提出改进方法的：

插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率
但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位

```java
public static void main(String [] args)
{
    int[]a={49，38，65，97，76，13，27，49，78，34，12，64，1};
        System.out.println("排序之前：");
        for(int i=0;i<a.length;i++)
        {
            System.out.print(a[i]+" ");
        }
        //希尔排序
        int d=a.length;
            while(true)
            {
                d=d/2;
                for(int x=0;x<d;x++)
                {
                    for(int i=x+d;i<a.length;i=i+d)
                    {
                        int temp=a[i];
                        int j;
                        for(j=i-d;j>=0&&a[j]>temp;j=j-d)
                        {
                            a[j+d]=a[j];
                        }
                        a[j+d]=temp;
                    }
                }
                if(d==1)
                {
                    break;
                }
            }
            System.out.println();
            System.out.println("排序之后：");
                for(int i=0;i<a.length;i++)
                {
                    System.out.print(a[i]+" ");
                }
    }

```

#### 时间复杂度

平均：根据步长序列的不同而不同

最好：O( n ) 最坏：( nlog^2n )

#### 空间复杂度

O( n )

